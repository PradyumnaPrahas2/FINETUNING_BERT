{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9983732,"sourceType":"datasetVersion","datasetId":6143698},{"sourceId":9983809,"sourceType":"datasetVersion","datasetId":6143753},{"sourceId":9992907,"sourceType":"datasetVersion","datasetId":6150238}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### BERT MODEL","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:02:50.575310Z","iopub.execute_input":"2024-11-18T09:02:50.575698Z","iopub.status.idle":"2024-11-18T09:02:50.580770Z","shell.execute_reply.started":"2024-11-18T09:02:50.575654Z","shell.execute_reply":"2024-11-18T09:02:50.579777Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### The bert-base model has a vocabulary size of 30522 (vocab_size) → vocab_size. \n### The maximum length of the input sequences 512 tokens → model_max_length.\n### Determines which side of the sequence to truncate when it exceeds the model_max_length. Right truncation means that ### tokens will be removed from the end of the sequence, left means tokens will be removed from start.","metadata":{}},{"cell_type":"markdown","source":"![](https://miro.medium.com/v2/resize:fit:1358/1*Qww2aaIdqrWVeNmo3AS0ZQ.png)","metadata":{}},{"cell_type":"markdown","source":"### token id's generation","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\nimport numpy as np\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\nlong_sentences = [\n    [\n        \"'When did Beyonce start becoming popular?\",\n        'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ '\n                            'bee-YON-say) (born September 4, 1981) is an '\n                            'American singer, songwriter, record producer and '\n                            'actress. Born and raised in Houston, Texas, she '\n                            'performed in various singing and dancing '\n                            'competitions as a child, and rose to fame in the '\n                            'late 1990s as lead singer of R&B girl-group '\n                            \"Destiny's Child. Managed by her father, Mathew \"\n                            \"Knowles, the group became one of the world's \"\n                            'best-selling girl groups of all time. Their '\n                            \"hiatus saw the release of Beyoncé's debut album, \"\n                            'Dangerously in Love (2003), which established her '\n                            'as a solo artist worldwide, earned five Grammy '\n                            'Awards and featured the Billboard Hot 100 '\n                            'number-one singles \"Crazy in Love\" and \"Baby '\n                            'Boy\".'\n    ]\n]\n\nl=sorted(long_sentences,key=len,reverse=True)\nmax_length=len(long_sentences[0][1])\nTOKEN_IDS=[]\ni=0\nSEGMENT_IDS=[]\nfor sentence in long_sentences:\n    encoded_input = tokenizer(\n        sentence[0],sentence[1],\n        max_length=max_length,      \n        truncation=True,     \n        padding=\"max_length\"\n    )\n    tokens = tokenizer.convert_ids_to_tokens(encoded_input[\"input_ids\"])\n    \n    print(f\"Question: {sentence[0][:]}...\")  \n#     print(f\"Answer:{sentence[1]:[:]}...\")\n    print(f\"Tokens: {tokens}...\")       \n    print(f\"Token IDs: {encoded_input['input_ids']}...\")\n    print(\"\\n\")\n#     print(\"Length of the sentence is\",len(sentence[0].split(\" \")))\n    print(\"Token shape for sentence is\",np.array([tokens]).shape)\n#     print(\"Length of Encoded Input of this sentence is\",len(encoded_input['input_ids'][:50]))\n    print(\"\\n\")\n    print(\"*********************************************************\\n\")\n    \n    \n    \n    \n    TOKEN_IDS.append(np.array(encoded_input['input_ids']))\n    SEGMENT_IDS.append(np.array([i for j in range(36)]))\n    i+=1","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:12:36.536453Z","iopub.execute_input":"2024-11-20T09:12:36.537446Z","iopub.status.idle":"2024-11-20T09:12:36.813807Z","shell.execute_reply.started":"2024-11-20T09:12:36.537406Z","shell.execute_reply":"2024-11-20T09:12:36.812483Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Question: 'When did Beyonce start becoming popular?...\nTokens: ['[CLS]', \"'\", 'when', 'did', 'beyonce', 'start', 'becoming', 'popular', '?', '[SEP]', 'beyonce', 'gi', '##selle', 'knowles', '-', 'carter', '(', '/', 'bi', '##ː', '##ˈ', '##j', '##ɒ', '##nse', '##ɪ', '/', 'bee', '-', 'yo', '##n', '-', 'say', ')', '(', 'born', 'september', '4', ',', '1981', ')', 'is', 'an', 'american', 'singer', ',', 'songwriter', ',', 'record', 'producer', 'and', 'actress', '.', 'born', 'and', 'raised', 'in', 'houston', ',', 'texas', ',', 'she', 'performed', 'in', 'various', 'singing', 'and', 'dancing', 'competitions', 'as', 'a', 'child', ',', 'and', 'rose', 'to', 'fame', 'in', 'the', 'late', '1990s', 'as', 'lead', 'singer', 'of', 'r', '&', 'b', 'girl', '-', 'group', 'destiny', \"'\", 's', 'child', '.', 'managed', 'by', 'her', 'father', ',', 'mathew', 'knowles', ',', 'the', 'group', 'became', 'one', 'of', 'the', 'world', \"'\", 's', 'best', '-', 'selling', 'girl', 'groups', 'of', 'all', 'time', '.', 'their', 'hiatus', 'saw', 'the', 'release', 'of', 'beyonce', \"'\", 's', 'debut', 'album', ',', 'dangerously', 'in', 'love', '(', '2003', ')', ',', 'which', 'established', 'her', 'as', 'a', 'solo', 'artist', 'worldwide', ',', 'earned', 'five', 'grammy', 'awards', 'and', 'featured', 'the', 'billboard', 'hot', '100', 'number', '-', 'one', 'singles', '\"', 'crazy', 'in', 'love', '\"', 'and', '\"', 'baby', 'boy', '\"', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']...\nToken IDs: [101, 1005, 2043, 2106, 20773, 2707, 3352, 2759, 1029, 102, 20773, 21025, 19358, 22815, 1011, 5708, 1006, 1013, 12170, 23432, 29715, 3501, 29678, 12325, 29685, 1013, 10506, 1011, 10930, 2078, 1011, 2360, 1007, 1006, 2141, 2244, 1018, 1010, 3261, 1007, 2003, 2019, 2137, 3220, 1010, 6009, 1010, 2501, 3135, 1998, 3883, 1012, 2141, 1998, 2992, 1999, 5395, 1010, 3146, 1010, 2016, 2864, 1999, 2536, 4823, 1998, 5613, 6479, 2004, 1037, 2775, 1010, 1998, 3123, 2000, 4476, 1999, 1996, 2397, 4134, 2004, 2599, 3220, 1997, 1054, 1004, 1038, 2611, 1011, 2177, 10461, 1005, 1055, 2775, 1012, 3266, 2011, 2014, 2269, 1010, 25436, 22815, 1010, 1996, 2177, 2150, 2028, 1997, 1996, 2088, 1005, 1055, 2190, 1011, 4855, 2611, 2967, 1997, 2035, 2051, 1012, 2037, 14221, 2387, 1996, 2713, 1997, 20773, 1005, 1055, 2834, 2201, 1010, 20754, 1999, 2293, 1006, 2494, 1007, 1010, 2029, 2511, 2014, 2004, 1037, 3948, 3063, 4969, 1010, 3687, 2274, 8922, 2982, 1998, 2956, 1996, 4908, 2980, 2531, 2193, 1011, 2028, 3895, 1000, 4689, 1999, 2293, 1000, 1998, 1000, 3336, 2879, 1000, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]...\n\n\nToken shape for sentence is (1, 694)\n\n\n*********************************************************\n\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"![](https://www.researchgate.net/publication/341040234/figure/fig2/AS:885864246833153@1588217903153/Architecture-of-the-BERT-classification-model.png)","metadata":{}},{"cell_type":"markdown","source":"### Segment Id's","metadata":{}},{"cell_type":"code","source":"# from transformers import BertTokenizer\n\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\n# sentences=long_sentences\n\n# max_length = 36 \n\n# encoded_pair_1 = tokenizer(\n#     sentences[0], sentences[1],\n#     max_length=max_length,\n#     padding=\"max_length\",\n#     truncation=True,\n#     return_tensors=\"pt\"\n# )\n\n# encoded_pair_2 = tokenizer(\n#     sentences[1], sentences[2],\n#     max_length=max_length,\n#     padding=\"max_length\",\n#     truncation=True,\n#     return_tensors=\"pt\"\n# )\n\n\n# print(\"Pair 1 - Input IDs:\", encoded_pair_1[\"input_ids\"])\n# print(\"Tensor shape: \",encoded_pair_1['input_ids'].shape)\n# print(\"Pair 1 - Segment IDs:\", encoded_pair_1[\"token_type_ids\"])\n\n# print(\"\\nPair 2 - Input IDs:\", encoded_pair_2[\"input_ids\"])\n# print(\"Tensor shape: \",encoded_pair_2['input_ids'].shape)\n# print(\"Pair 2 - Segment IDs:\", encoded_pair_2[\"token_type_ids\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-11-14T14:35:59.092667Z","iopub.execute_input":"2024-11-14T14:35:59.093113Z","iopub.status.idle":"2024-11-14T14:35:59.099186Z","shell.execute_reply.started":"2024-11-14T14:35:59.093078Z","shell.execute_reply":"2024-11-14T14:35:59.098097Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Postional Id's","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef generate_positional_ids(sentences, max_length):\n    \n    positional_ids = torch.arange(max_length).unsqueeze(0).expand(len(sentences), -1)\n    \n    return positional_ids\n\n# Example usage\nmax_length=max_length\n  # Specify the maximum length\npositional_ids = generate_positional_ids(long_sentences, max_length)\n\nprint(\" Complete Positional IDs:\\n\", positional_ids)\nprint(\"Shapes are: \")\nPOSITIONAL_IDS=[]\nfor tensors in positional_ids:\n    print(\"********************************************\")\n    print(tensors)\n    print(np.array([tensors]).shape)\n    print(\"********************************************\")\n    POSITIONAL_IDS.append(np.array(tensors))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:12:46.264308Z","iopub.execute_input":"2024-11-20T09:12:46.264696Z","iopub.status.idle":"2024-11-20T09:12:46.280390Z","shell.execute_reply.started":"2024-11-20T09:12:46.264661Z","shell.execute_reply":"2024-11-20T09:12:46.279239Z"},"trusted":true},"outputs":[{"name":"stdout","text":" Complete Positional IDs:\n tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n         308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n         392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n         420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n         448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n         462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n         490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n         504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n         518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,\n         532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n         546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n         560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,\n         574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,\n         588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n         602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,\n         616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629,\n         630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643,\n         644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n         658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671,\n         672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n         686, 687, 688, 689, 690, 691, 692, 693]])\nShapes are: \n********************************************\ntensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n        504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n        518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,\n        532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n        546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n        560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,\n        574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,\n        588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n        602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,\n        616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629,\n        630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643,\n        644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n        658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671,\n        672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n        686, 687, 688, 689, 690, 691, 692, 693])\n(1, 694)\n********************************************\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"TOKEN_IDS=np.array(TOKEN_IDS)\nPOSITIONAL_IDS=np.array(POSITIONAL_IDS)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:12:50.037299Z","iopub.execute_input":"2024-11-20T09:12:50.037689Z","iopub.status.idle":"2024-11-20T09:12:50.042861Z","shell.execute_reply.started":"2024-11-20T09:12:50.037652Z","shell.execute_reply":"2024-11-20T09:12:50.041610Z"},"trusted":true},"outputs":[],"execution_count":64},{"cell_type":"code","source":"print(TOKEN_IDS.shape)\n# print(SEGMENT_IDS.shape)\nprint(POSITIONAL_IDS.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:12:52.274780Z","iopub.execute_input":"2024-11-20T09:12:52.275203Z","iopub.status.idle":"2024-11-20T09:12:52.280609Z","shell.execute_reply.started":"2024-11-20T09:12:52.275147Z","shell.execute_reply":"2024-11-20T09:12:52.279546Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(1, 694)\n(1, 694)\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"combined_ids=TOKEN_IDS+POSITIONAL_IDS\nprint(combined_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:12:53.896804Z","iopub.execute_input":"2024-11-20T09:12:53.897266Z","iopub.status.idle":"2024-11-20T09:12:53.903180Z","shell.execute_reply.started":"2024-11-20T09:12:53.897168Z","shell.execute_reply":"2024-11-20T09:12:53.902065Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(1, 694)\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"combined_ids","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:12:54.955642Z","iopub.execute_input":"2024-11-20T09:12:54.956420Z","iopub.status.idle":"2024-11-20T09:12:54.964717Z","shell.execute_reply.started":"2024-11-20T09:12:54.956379Z","shell.execute_reply":"2024-11-20T09:12:54.963567Z"},"trusted":true},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"array([[  101,  1006,  2045,  2109, 20777,  2712,  3358,  2766,  1037,\n          111, 20783, 21036, 19370, 22828,  1025,  5723,  1022,  1030,\n        12188, 23451, 29735,  3522, 29700, 12348, 29709,  1038, 10532,\n         1038, 10958,  2107,  1041,  2391,  1039,  1039,  2175,  2279,\n         1054,  1047,  3299,  1046,  2043,  2060,  2179,  3263,  1054,\n         6054,  1056,  2548,  3183,  2047,  3933,  1063,  2193,  2051,\n         3046,  2054,  5451,  1067,  3204,  1069,  2076,  2925,  2061,\n         2599,  4887,  2063,  5679,  6546,  2072,  1106,  2845,  1081,\n         2070,  3196,  2074,  4551,  2075,  2073,  2475,  4213,  2084,\n         2680,  3302,  2080,  1138,  1089,  1124,  2698,  1099,  2266,\n        10551,  1096,  1147,  2868,  1106,  3361,  2107,  2111,  2367,\n         1109, 25536, 22916,  1112,  2099,  2281,  2255,  2134,  2104,\n         2104,  2197,  1115,  1166,  2302,  1124,  4969,  2726,  3083,\n         2114,  2153,  2170,  1132,  2158, 14343,  2510,  2120,  2838,\n         2123, 20900,  1133,  1184,  2964,  2332,  1142, 20887,  2133,\n         2428,  1142,  2631,  1145,  1149,  2169,  2652,  2156,  2147,\n         1181,  4093,  3209,  5116,  1158,  3836,  2424,  9073,  3134,\n         2151,  3110,  2151,  5064,  3137,  2689,  2352,  1171,  2189,\n         4057,  1163,  4853,  2164,  2459,  1167,  2166,  1169,  3506,\n         3050,  1172,  1185,   276,   175,   176,   177,   178,   179,\n          180,   181,   182,   183,   184,   185,   186,   187,   188,\n          189,   190,   191,   192,   193,   194,   195,   196,   197,\n          198,   199,   200,   201,   202,   203,   204,   205,   206,\n          207,   208,   209,   210,   211,   212,   213,   214,   215,\n          216,   217,   218,   219,   220,   221,   222,   223,   224,\n          225,   226,   227,   228,   229,   230,   231,   232,   233,\n          234,   235,   236,   237,   238,   239,   240,   241,   242,\n          243,   244,   245,   246,   247,   248,   249,   250,   251,\n          252,   253,   254,   255,   256,   257,   258,   259,   260,\n          261,   262,   263,   264,   265,   266,   267,   268,   269,\n          270,   271,   272,   273,   274,   275,   276,   277,   278,\n          279,   280,   281,   282,   283,   284,   285,   286,   287,\n          288,   289,   290,   291,   292,   293,   294,   295,   296,\n          297,   298,   299,   300,   301,   302,   303,   304,   305,\n          306,   307,   308,   309,   310,   311,   312,   313,   314,\n          315,   316,   317,   318,   319,   320,   321,   322,   323,\n          324,   325,   326,   327,   328,   329,   330,   331,   332,\n          333,   334,   335,   336,   337,   338,   339,   340,   341,\n          342,   343,   344,   345,   346,   347,   348,   349,   350,\n          351,   352,   353,   354,   355,   356,   357,   358,   359,\n          360,   361,   362,   363,   364,   365,   366,   367,   368,\n          369,   370,   371,   372,   373,   374,   375,   376,   377,\n          378,   379,   380,   381,   382,   383,   384,   385,   386,\n          387,   388,   389,   390,   391,   392,   393,   394,   395,\n          396,   397,   398,   399,   400,   401,   402,   403,   404,\n          405,   406,   407,   408,   409,   410,   411,   412,   413,\n          414,   415,   416,   417,   418,   419,   420,   421,   422,\n          423,   424,   425,   426,   427,   428,   429,   430,   431,\n          432,   433,   434,   435,   436,   437,   438,   439,   440,\n          441,   442,   443,   444,   445,   446,   447,   448,   449,\n          450,   451,   452,   453,   454,   455,   456,   457,   458,\n          459,   460,   461,   462,   463,   464,   465,   466,   467,\n          468,   469,   470,   471,   472,   473,   474,   475,   476,\n          477,   478,   479,   480,   481,   482,   483,   484,   485,\n          486,   487,   488,   489,   490,   491,   492,   493,   494,\n          495,   496,   497,   498,   499,   500,   501,   502,   503,\n          504,   505,   506,   507,   508,   509,   510,   511,   512,\n          513,   514,   515,   516,   517,   518,   519,   520,   521,\n          522,   523,   524,   525,   526,   527,   528,   529,   530,\n          531,   532,   533,   534,   535,   536,   537,   538,   539,\n          540,   541,   542,   543,   544,   545,   546,   547,   548,\n          549,   550,   551,   552,   553,   554,   555,   556,   557,\n          558,   559,   560,   561,   562,   563,   564,   565,   566,\n          567,   568,   569,   570,   571,   572,   573,   574,   575,\n          576,   577,   578,   579,   580,   581,   582,   583,   584,\n          585,   586,   587,   588,   589,   590,   591,   592,   593,\n          594,   595,   596,   597,   598,   599,   600,   601,   602,\n          603,   604,   605,   606,   607,   608,   609,   610,   611,\n          612,   613,   614,   615,   616,   617,   618,   619,   620,\n          621,   622,   623,   624,   625,   626,   627,   628,   629,\n          630,   631,   632,   633,   634,   635,   636,   637,   638,\n          639,   640,   641,   642,   643,   644,   645,   646,   647,\n          648,   649,   650,   651,   652,   653,   654,   655,   656,\n          657,   658,   659,   660,   661,   662,   663,   664,   665,\n          666,   667,   668,   669,   670,   671,   672,   673,   674,\n          675,   676,   677,   678,   679,   680,   681,   682,   683,\n          684,   685,   686,   687,   688,   689,   690,   691,   692,\n          693]])"},"metadata":{}}],"execution_count":67},{"cell_type":"markdown","source":"## EMBEDDINGS","metadata":{}},{"cell_type":"markdown","source":"![Architecture](data:image/jpeg;base64,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)","metadata":{}},{"cell_type":"markdown","source":"Token embeddings are generated by mapping discrete token IDs from a vocabulary to dense vector representations using an embedding layer, allowing models to work with numerical representations of the tokens.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\ndef generate_token_embeddings(token_ids, vocab_size, hidden_size):\n   \n    embedding_layer = nn.Embedding(vocab_size, hidden_size)\n\n    \n    token_tensor = torch.nn.utils.rnn.pad_sequence(\n        [torch.tensor(tokens) for tokens in token_ids],\n        batch_first=True\n    )\n\n\n    embeddings = embedding_layer(token_tensor)\n\n    return embeddings\n\n\nvocab_size = 30522\nhidden_size = 768\n\ntoken_embeddings = generate_token_embeddings(TOKEN_IDS, vocab_size, hidden_size)\n\nprint(\"Token Embeddings Shape:\", token_embeddings.shape)  \n\nfor i in range(len(long_sentences)):\n    print(\"\\nToken Embeddings for Sentence:\\n\",i, token_embeddings[i])\n    print(\"Shape of the tensor: \",token_embeddings[i].shape)\n    print(\"***************************************************************8\")\n    \nprint(\"Final Token Embeddings Shape: \\n\",token_embeddings.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:12:58.346862Z","iopub.execute_input":"2024-11-20T09:12:58.347254Z","iopub.status.idle":"2024-11-20T09:12:58.592814Z","shell.execute_reply.started":"2024-11-20T09:12:58.347221Z","shell.execute_reply":"2024-11-20T09:12:58.591622Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Token Embeddings Shape: torch.Size([1, 694, 768])\n\nToken Embeddings for Sentence:\n 0 tensor([[ 1.0425, -0.7983,  1.3874,  ...,  0.5769, -0.6412, -0.9604],\n        [-0.8628,  0.8798, -0.3854,  ...,  1.1804, -0.8429,  1.1155],\n        [ 0.9445, -1.1982, -1.2204,  ...,  0.4016, -0.4222,  1.3212],\n        ...,\n        [-0.5823, -0.1074,  0.4987,  ...,  0.3271, -1.1970,  0.7723],\n        [-0.5823, -0.1074,  0.4987,  ...,  0.3271, -1.1970,  0.7723],\n        [-0.5823, -0.1074,  0.4987,  ...,  0.3271, -1.1970,  0.7723]],\n       grad_fn=<SelectBackward0>)\nShape of the tensor:  torch.Size([694, 768])\n***************************************************************8\nFinal Token Embeddings Shape: \n torch.Size([1, 694, 768])\n","output_type":"stream"}],"execution_count":68},{"cell_type":"markdown","source":"### Positional Embeddings","metadata":{}},{"cell_type":"markdown","source":"Positional embeddings are generated by creating a fixed-size embedding for each position in the input sequence,  to provide information about the relative or absolute position of tokens, allowing the model to capture the order of the tokens in a sequence.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\ndef generate_positional_embeddings(batch_size, max_length, hidden_size):\n    positional_embeddings = nn.Embedding(max_length, hidden_size)\n    positional_ids = torch.arange(max_length)\n    embeddings = positional_embeddings(positional_ids)\n    positional_embeddings_with_batch = embeddings.unsqueeze(0).expand(batch_size, -1, -1)\n    return positional_embeddings_with_batch\n\nbatch_size = 1\nmax_length = max_length\nhidden_size = 768  \n\npositional_embeddings = generate_positional_embeddings(batch_size, max_length, hidden_size)\nfor i in range(batch_size):\n    print(\"Positional Embeddings:\", positional_embeddings[i])\n    print(\"Shape: \",positional_embeddings[i].shape)\n    print(\"********************************************************************\\n\")\nprint(\"\\nFinal Positional Embeddings Shape:\\n\", positional_embeddings.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:13:00.303022Z","iopub.execute_input":"2024-11-20T09:13:00.303424Z","iopub.status.idle":"2024-11-20T09:13:00.319570Z","shell.execute_reply.started":"2024-11-20T09:13:00.303390Z","shell.execute_reply":"2024-11-20T09:13:00.318481Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Positional Embeddings: tensor([[ 1.1207, -0.6018, -0.5285,  ..., -0.6681,  1.0085, -0.6154],\n        [ 0.0351,  0.6104, -0.1470,  ..., -0.2058, -0.5065, -1.0210],\n        [ 0.5969, -2.2711,  0.6211,  ...,  1.6626,  1.9559,  0.9129],\n        ...,\n        [-1.3852,  0.4988, -0.8363,  ...,  0.6938,  0.2292, -0.4195],\n        [ 0.9652,  2.8553, -2.5552,  ..., -1.6781,  0.6370, -0.0391],\n        [-0.4293,  0.1476,  1.1714,  ..., -0.4472, -0.9187, -1.3772]],\n       grad_fn=<SelectBackward0>)\nShape:  torch.Size([694, 768])\n********************************************************************\n\n\nFinal Positional Embeddings Shape:\n torch.Size([1, 694, 768])\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"### Segment Embeddings","metadata":{}},{"cell_type":"markdown","source":"Segment embeddings are generated by using an embedding layer that assigns a unique dense vector to each segment (or sentence) in the input, typically initialized with two embeddings (for segment IDs 0 and 1) to differentiate between segments in tasks like sentence pair classification, allowing the model to distinguish which tokens belong to which segment.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\ndef generate_segment_embeddings(segment_ids, hidden_size):\n    # Create an embedding layer for two segments (0 and 1)\n    segment_embeddings = nn.Embedding(2, hidden_size)\n    \n    # Get the segment embeddings using the segment IDs\n    embeddings = segment_embeddings(segment_ids)\n    \n    return embeddings\n\n# Example parameters\nbatch_size = 1\nmax_length = max_length\nhidden_size = 768  \n\n# Example segment IDs: a tensor of shape (batch_size, max_length)\n# Here, the first half is segment 0 and the second half is segment 1\nSEGMENT_IDS = torch.zeros((batch_size, max_length), dtype=torch.long)\nSEGMENT_IDS[:, max_length // 2:] = 1\n\n# Generate segment embeddings\nsegment_embeddings = generate_segment_embeddings(SEGMENT_IDS, hidden_size)\nfor i in range(batch_size):\n    print(\"Segment Embedding: \",segment_embeddings[i])\n    print(\"Shape: \",segment_embeddings[i].shape)\n    print(\"***************************************************************************\")\n# Output shape and embeddingsape:\", segment_embeddings.shape)  # Should be (batch_size, max_length, hidden_size)\nprint(\"\\nFinal Segment Embeddings:\\n\", segment_embeddings.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:13:03.119749Z","iopub.execute_input":"2024-11-20T09:13:03.120433Z","iopub.status.idle":"2024-11-20T09:13:03.131645Z","shell.execute_reply.started":"2024-11-20T09:13:03.120392Z","shell.execute_reply":"2024-11-20T09:13:03.130429Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Segment Embedding:  tensor([[ 1.2448,  1.3766, -0.2539,  ...,  0.7216, -0.4996, -0.6447],\n        [ 1.2448,  1.3766, -0.2539,  ...,  0.7216, -0.4996, -0.6447],\n        [ 1.2448,  1.3766, -0.2539,  ...,  0.7216, -0.4996, -0.6447],\n        ...,\n        [ 0.3944,  0.9136, -0.0994,  ...,  0.6758, -0.1365, -0.7785],\n        [ 0.3944,  0.9136, -0.0994,  ...,  0.6758, -0.1365, -0.7785],\n        [ 0.3944,  0.9136, -0.0994,  ...,  0.6758, -0.1365, -0.7785]],\n       grad_fn=<SelectBackward0>)\nShape:  torch.Size([694, 768])\n***************************************************************************\n\nFinal Segment Embeddings:\n torch.Size([1, 694, 768])\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"# import torch\n# import torch.nn.functional as F\n# import random\n# segment_embedding_1 = torch.rand((36, 768))\n# segment_embedding_2 = torch.rand((36, 768))\n\n# cosine_similarity = F.cosine_similarity(segment_embedding_1, segment_embedding_2)\n\n# print(\"Cosine Similarity:\", cosine_similarity)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-14T14:35:59.552123Z","iopub.execute_input":"2024-11-14T14:35:59.552443Z","iopub.status.idle":"2024-11-14T14:35:59.558076Z","shell.execute_reply.started":"2024-11-14T14:35:59.552409Z","shell.execute_reply":"2024-11-14T14:35:59.557240Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"combined_embeddings=token_embeddings+positional_embeddings\ncombined_embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:13:05.911926Z","iopub.execute_input":"2024-11-20T09:13:05.912335Z","iopub.status.idle":"2024-11-20T09:13:05.919833Z","shell.execute_reply.started":"2024-11-20T09:13:05.912296Z","shell.execute_reply":"2024-11-20T09:13:05.918778Z"},"trusted":true},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 694, 768])"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"combined_embeddings","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:13:07.283310Z","iopub.execute_input":"2024-11-20T09:13:07.283685Z","iopub.status.idle":"2024-11-20T09:13:07.292215Z","shell.execute_reply.started":"2024-11-20T09:13:07.283653Z","shell.execute_reply":"2024-11-20T09:13:07.291260Z"},"trusted":true},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 2.1632, -1.4001,  0.8589,  ..., -0.0912,  0.3673, -1.5758],\n         [-0.8276,  1.4902, -0.5323,  ...,  0.9746, -1.3494,  0.0946],\n         [ 1.5413, -3.4692, -0.5993,  ...,  2.0642,  1.5338,  2.2341],\n         ...,\n         [-1.9675,  0.3914, -0.3375,  ...,  1.0209, -0.9678,  0.3528],\n         [ 0.3829,  2.7479, -2.0564,  ..., -1.3509, -0.5600,  0.7332],\n         [-1.0116,  0.0402,  1.6702,  ..., -0.1201, -2.1157, -0.6049]]],\n       grad_fn=<AddBackward0>)"},"metadata":{}}],"execution_count":72},{"cell_type":"markdown","source":"### Attention Mask","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef generate_attention_mask(combined_embeddings):\n    batch_size, max_length, _ = combined_embeddings.shape\n    \n    attention_mask = (combined_embeddings != 0).any(dim=-1).long()\n    \n    return attention_mask\n\nbatch_size = 1\nmax_length = max_length\nhidden_size = 768\n\n\ncombined_embeddings = torch.rand((batch_size, max_length, hidden_size))  \n\nattention_mask = generate_attention_mask(combined_embeddings)\n\n\nprint(\"Attention Mask Shape:\", attention_mask.shape)  \nprint(\"Attention Mask:\\n\", attention_mask)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:13:09.553167Z","iopub.execute_input":"2024-11-20T09:13:09.553620Z","iopub.status.idle":"2024-11-20T09:13:09.571644Z","shell.execute_reply.started":"2024-11-20T09:13:09.553581Z","shell.execute_reply":"2024-11-20T09:13:09.570546Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Attention Mask Shape: torch.Size([1, 694])\nAttention Mask:\n tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","output_type":"stream"}],"execution_count":73},{"cell_type":"markdown","source":"### Attention Mechanism","metadata":{}},{"cell_type":"markdown","source":"## 1. Input Preparation\n### Input Tensor: The input to the multi-head attention layer is a tensor of shape (batch_size, seq_length, hidden_size), where:\n### batch_size is the number of input sequences processed simultaneously.\n### seq_length is the length of each input sequence (number of tokens).\n### hidden_size is the dimensionality of each token's embedding.\n\n## 2. Linear Transformations\n### Linear Layers: Three separate linear transformations are applied to the input tensor to produce the queries, keys, and values:\n### Queries: Generated by passing the input through a linear layer designed for queries.\n### Keys: Generated by passing the input through a linear layer designed for keys.\n### Values: Generated by passing the input through a linear layer designed for values.\n\n## 3. Shape of Queries, Keys, and Values\n### After the linear transformations, the shapes of the resulting matrices are:\n### Queries Matrix: (batch_size, seq_length, hidden_size)\n### Keys Matrix: (batch_size, seq_length, hidden_size)\n### Values Matrix: (batch_size, seq_length, hidden_size)\n\n## 4. Reshaping for Multi-Head Attention\n### Multi-Head Reshaping: Each of the queries, keys, and values matrices is reshaped to allow for multi-head attention:\n### The matrices are reshaped to (batch_size, num_heads, seq_length, head_dim), where:\n### head_dim = hidden_size / num_heads\n### This involves splitting the hidden_size dimension into multiple heads, enabling the model to learn different representations in parallel.\n\n## 5. Output of the Transformation\n# # 1. ### Final Output: The resulting queries, keys, and values matrices are used in the attention computation. Each matrix retains the context of the input sequences while allowing the model to focus on different parts of the input through attention scores.","metadata":{}},{"cell_type":"markdown","source":"![](https://www.researchgate.net/publication/366985717/figure/fig4/AS:11431281112323043@1673383393149/Scaled-Dot-Product-Attention-mapping-a-query-and-a-set-of-key-value-pairs-to-an-output.png)","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, hidden_size, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        self.num_heads = num_heads\n        self.head_dim = hidden_size // num_heads\n\n        assert (\n            hidden_size % num_heads == 0\n        ), \"hidden_size must be divisible by num_heads\"\n\n        self.query_linear = nn.Linear(hidden_size, hidden_size)\n        self.key_linear = nn.Linear(hidden_size, hidden_size)\n        self.value_linear = nn.Linear(hidden_size, hidden_size)\n        self.fc_out = nn.Linear(hidden_size, hidden_size)\n\n    def forward(self, x):\n        batch_size, seq_length, hidden_size = x.size()\n\n        queries = self.query_linear(x)  \n        keys = self.key_linear(x)\n        values = self.value_linear(x)\n\n        # Print the query, key, and value matrices\n        print(\"\\nQueries Matrix:- \",queries)\n        print(\"Queries Matrix Shape:\", queries.shape)\n        print(\"\\nKeys Matrix:- \",keys)\n        print(\"Keys Matrix Shape:\", keys.shape)\n        print(\"\\nValues Matrix:- \",values)\n        print(\"Values Matrix Shape:\", values.shape)\n\n        # Reshape for multi-head attention\n        queries = queries.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_length, head_dim)\n        keys = keys.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_length, head_dim)\n        values = values.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_length, head_dim)\n        energy = torch.einsum(\"nhqd,nhkd->nhqk\", [queries, keys])  # (batch_size, num_heads, seq_length, seq_length)\n\n        attention_scores = energy / (self.head_dim ** 0.5)\n        print(\"Attention scores shape: \",attention_scores.shape)\n        attention = torch.softmax(energy / (self.head_dim ** 0.5), dim=3)  # Scale and softmax\n        print(\"Attention score shape after softmax: \",attention.shape)\n        out = torch.einsum(\"nhql,nhld->nhqd\", [attention, values]).reshape(batch_size, seq_length, hidden_size)  # (batch_size, seq_length, hidden_size)\n        out = self.fc_out(out)  # Final linear layer\n\n        return out\n\n\nbatch_size = 1\nseq_length = max_length\nhidden_size = 768\nnum_heads = 12\n\nattention_layer = MultiHeadAttention(hidden_size, num_heads)\n\n\ncombined_embeddings = combined_embeddings\n\n\noutput_embeddings = attention_layer(combined_embeddings)\n\nprint(\"Output Embeddings Shape:\", output_embeddings.shape)  \n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:13:15.785934Z","iopub.execute_input":"2024-11-20T09:13:15.786327Z","iopub.status.idle":"2024-11-20T09:13:15.936968Z","shell.execute_reply.started":"2024-11-20T09:13:15.786294Z","shell.execute_reply":"2024-11-20T09:13:15.935902Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nQueries Matrix:-  tensor([[[-0.7487,  0.1315, -0.3163,  ...,  0.0329, -0.1276,  0.2806],\n         [-0.6895, -0.2051, -0.2112,  ...,  0.4104, -0.1640,  0.3503],\n         [-0.4780, -0.0153,  0.2025,  ...,  0.1060, -0.1197,  0.4763],\n         ...,\n         [-0.7116,  0.1268,  0.2733,  ...,  0.0900, -0.1892,  0.3336],\n         [-0.6334,  0.1781,  0.2598,  ...,  0.4137,  0.0146,  0.2321],\n         [-0.6642,  0.0908, -0.0684,  ...,  0.3256,  0.0240,  0.4736]]],\n       grad_fn=<ViewBackward0>)\nQueries Matrix Shape: torch.Size([1, 694, 768])\n\nKeys Matrix:-  tensor([[[-0.1145, -0.0394,  0.1591,  ..., -0.2300,  0.0603,  0.2490],\n         [-0.4580, -0.1131,  0.4583,  ..., -0.2053,  0.1089,  0.4305],\n         [-0.4292,  0.0532,  0.2541,  ...,  0.0468, -0.1139,  0.4879],\n         ...,\n         [-0.1616, -0.0476,  0.2804,  ...,  0.0341,  0.0465,  0.1618],\n         [-0.1083, -0.1008,  0.3135,  ..., -0.5782, -0.1123, -0.0492],\n         [-0.8932, -0.1812, -0.0311,  ..., -0.3090,  0.1945,  0.1943]]],\n       grad_fn=<ViewBackward0>)\nKeys Matrix Shape: torch.Size([1, 694, 768])\n\nValues Matrix:-  tensor([[[ 0.0885, -0.0734,  0.1148,  ...,  0.1345, -0.2040, -0.3696],\n         [ 0.0939,  0.0943,  0.0935,  ..., -0.0979, -0.1297, -0.3193],\n         [ 0.1657, -0.0095, -0.0442,  ...,  0.3714,  0.2629, -0.3081],\n         ...,\n         [ 0.2093,  0.3178, -0.3336,  ...,  0.2194,  0.1319, -0.5607],\n         [-0.2047,  0.0829,  0.0938,  ...,  0.0794,  0.5062, -0.4919],\n         [-0.0152,  0.2575, -0.3407,  ...,  0.1253,  0.1005, -0.7452]]],\n       grad_fn=<ViewBackward0>)\nValues Matrix Shape: torch.Size([1, 694, 768])\nAttention scores shape:  torch.Size([1, 12, 694, 694])\nAttention score shape after softmax:  torch.Size([1, 12, 694, 694])\nOutput Embeddings Shape: torch.Size([1, 694, 768])\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"output_embeddings","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:13:19.114419Z","iopub.execute_input":"2024-11-20T09:13:19.114823Z","iopub.status.idle":"2024-11-20T09:13:19.123874Z","shell.execute_reply.started":"2024-11-20T09:13:19.114785Z","shell.execute_reply":"2024-11-20T09:13:19.122775Z"},"trusted":true},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"tensor([[[-0.1941,  0.1387,  0.3639,  ...,  0.1683, -0.1276, -0.2720],\n         [-0.1942,  0.1389,  0.3640,  ...,  0.1682, -0.1275, -0.2721],\n         [-0.1940,  0.1389,  0.3640,  ...,  0.1684, -0.1275, -0.2719],\n         ...,\n         [-0.0108,  0.1572, -0.0082,  ..., -0.0688,  0.2868, -0.4025],\n         [-0.0108,  0.1572, -0.0082,  ..., -0.0687,  0.2867, -0.4025],\n         [-0.0106,  0.1570, -0.0083,  ..., -0.0689,  0.2864, -0.4023]]],\n       grad_fn=<ViewBackward0>)"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"class QAHead(nn.Module):\n    def __init__(self, hidden_size):\n        super(QAHead, self).__init__()\n        self.start_logits = nn.Linear(hidden_size, 1)\n        self.end_logits = nn.Linear(hidden_size, 1)\n\n    def forward(self, embeddings):\n        start_logits = self.start_logits(embeddings).squeeze(-1)  \n        end_logits = self.end_logits(embeddings).squeeze(-1)      \n        return start_logits, end_logits","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:14:01.996359Z","iopub.execute_input":"2024-11-20T09:14:01.996742Z","iopub.status.idle":"2024-11-20T09:14:02.003362Z","shell.execute_reply.started":"2024-11-20T09:14:01.996706Z","shell.execute_reply":"2024-11-20T09:14:02.002046Z"},"trusted":true},"outputs":[],"execution_count":85},{"cell_type":"code","source":"qa_head = QAHead(hidden_size)\nstart_logits, end_logits = qa_head(output_embeddings)\n\nprint(\"Start Logits Shape:\", start_logits.shape)  \nprint(\"End Logits Shape:\", end_logits.shape)      \n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:14:24.610228Z","iopub.execute_input":"2024-11-20T09:14:24.610971Z","iopub.status.idle":"2024-11-20T09:14:24.617939Z","shell.execute_reply.started":"2024-11-20T09:14:24.610933Z","shell.execute_reply":"2024-11-20T09:14:24.616839Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Start Logits Shape: torch.Size([1, 694])\nEnd Logits Shape: torch.Size([1, 694])\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"start_logits,end_logits","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:14:25.883077Z","iopub.execute_input":"2024-11-20T09:14:25.883992Z","iopub.status.idle":"2024-11-20T09:14:25.902440Z","shell.execute_reply.started":"2024-11-20T09:14:25.883953Z","shell.execute_reply":"2024-11-20T09:14:25.901168Z"},"trusted":true},"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"(tensor([[ 0.0649,  0.0648,  0.0649,  0.0650,  0.0650,  0.0649,  0.0648,  0.0651,\n           0.0649,  0.0651,  0.0650,  0.0651,  0.0648,  0.0650,  0.0649,  0.0649,\n           0.0648,  0.0649,  0.0649,  0.0650,  0.0652,  0.0649,  0.0648,  0.0648,\n           0.0649,  0.0648,  0.0650,  0.0650,  0.0649,  0.0649,  0.0649,  0.0650,\n           0.0648,  0.0649,  0.0649,  0.0649,  0.0650,  0.0649,  0.0650,  0.0651,\n           0.0650,  0.0650,  0.0649,  0.0649,  0.0650,  0.0650,  0.0649,  0.0649,\n           0.0651,  0.0650,  0.0648,  0.0649,  0.0649,  0.0650,  0.0649,  0.0649,\n           0.0649,  0.0978,  0.2859,  0.2860,  0.2861,  0.2860,  0.2859,  0.2861,\n           0.2860,  0.2860,  0.2860,  0.2862,  0.2860,  0.2860,  0.2859,  0.2861,\n           0.2860,  0.2861,  0.2860,  0.2861,  0.2861,  0.2860,  0.2860,  0.2860,\n           0.2861,  0.2860,  0.2861,  0.2859,  0.2859,  0.2860,  0.2860,  0.2860,\n           0.2859,  0.2860,  0.2861,  0.2861,  0.2861,  0.2859,  0.2861,  0.2861,\n           0.2859,  0.2861,  0.2862,  0.2859,  0.2860,  0.2861,  0.2860,  0.2859,\n           0.2860,  0.2862,  0.2861,  0.2860,  0.2861,  0.2860,  0.2860,  0.2860,\n           0.2861,  0.2861,  0.2861,  0.1928, -0.0180, -0.0180, -0.0179, -0.0179,\n          -0.0178, -0.0180, -0.0179, -0.0181, -0.0179, -0.0179, -0.0179, -0.0179,\n          -0.0179, -0.0179, -0.0178, -0.0179, -0.0179, -0.0179, -0.0179, -0.0179,\n          -0.0179, -0.0179, -0.0179, -0.0179, -0.0179, -0.0179, -0.0179, -0.0178,\n          -0.0181, -0.0179, -0.0179, -0.0179, -0.0177, -0.0180, -0.0181, -0.0179,\n          -0.0179, -0.0179, -0.0177, -0.0179, -0.0179, -0.0178, -0.0179, -0.0179,\n          -0.0180, -0.0179, -0.0178, -0.0179, -0.0181, -0.0180, -0.0178, -0.0179,\n          -0.0180, -0.0180, -0.0180, -0.0178, -0.0178,  0.0176,  0.0181,  0.0180,\n           0.0182,  0.0180,  0.0179,  0.0180,  0.0180,  0.0180,  0.0181,  0.0181,\n           0.0181,  0.0181,  0.0180,  0.0181,  0.0181,  0.0181,  0.0180,  0.0181,\n           0.0180,  0.0181,  0.0180,  0.0179,  0.0180,  0.0181,  0.0180,  0.0180,\n           0.0181,  0.0182,  0.0180,  0.0180,  0.0181,  0.0181,  0.0182,  0.0182,\n           0.0181,  0.0181,  0.0179,  0.0181,  0.0180,  0.0180,  0.0180,  0.0180,\n           0.0181,  0.0180,  0.0181,  0.0180,  0.0181,  0.0180,  0.0179,  0.0180,\n           0.0181,  0.0181,  0.0182,  0.0182,  0.0180,  0.0181,  0.0180, -0.0604,\n          -0.1637, -0.1637, -0.1637, -0.1637, -0.1636, -0.1638, -0.1637, -0.1638,\n          -0.1636, -0.1636, -0.1637, -0.1637, -0.1637, -0.1637, -0.1636, -0.1637,\n          -0.1636, -0.1637, -0.1637, -0.1638, -0.1637, -0.1637, -0.1637, -0.1637,\n          -0.1637, -0.1637, -0.1637, -0.1637, -0.1638, -0.1637, -0.1638, -0.1638,\n          -0.1637, -0.1637, -0.1636, -0.1637, -0.1637, -0.1638, -0.1637, -0.1637,\n          -0.1638, -0.1637, -0.1638, -0.1637, -0.1636, -0.1637, -0.1636, -0.1637,\n          -0.1637, -0.1637, -0.1639, -0.1637, -0.1636, -0.1636, -0.1636, -0.1637,\n          -0.1638,  0.1817,  0.1383,  0.1382,  0.1382,  0.1382,  0.1383,  0.1384,\n           0.1383,  0.1383,  0.1381,  0.1384,  0.1382,  0.1382,  0.1383,  0.1381,\n           0.1382,  0.1382,  0.1382,  0.1383,  0.1382,  0.1382,  0.1383,  0.1382,\n           0.1383,  0.1383,  0.1382,  0.1382,  0.1382,  0.1383,  0.1382,  0.1383,\n           0.1382,  0.1383,  0.1383,  0.1381,  0.1382,  0.1382,  0.1383,  0.1383,\n           0.1382,  0.1382,  0.1383,  0.1383,  0.1383,  0.1384,  0.1382,  0.1384,\n           0.1382,  0.1385,  0.1383,  0.1383,  0.1382,  0.1382,  0.1383,  0.1383,\n           0.1383,  0.1383,  0.1384,  0.1023,  0.1025,  0.1024,  0.1026,  0.1025,\n           0.1026,  0.1025,  0.1025,  0.1025,  0.1026,  0.1025,  0.1024,  0.1025,\n           0.1024,  0.1024,  0.1025,  0.1025,  0.1026,  0.1024,  0.1025,  0.1024,\n           0.1026,  0.1027,  0.1025,  0.1024,  0.1024,  0.1026,  0.1023,  0.1025,\n           0.1024,  0.1024,  0.1024,  0.1025,  0.1026,  0.1025,  0.1025,  0.1025,\n           0.1024,  0.1024,  0.1024,  0.1025,  0.1026,  0.1025,  0.1025,  0.1025,\n           0.1025,  0.1025,  0.1025,  0.1025,  0.1025,  0.1024,  0.1025,  0.1023,\n           0.1025,  0.1023,  0.1025,  0.1024,  0.0544,  0.0123,  0.0121,  0.0122,\n           0.0123,  0.0122,  0.0123,  0.0122,  0.0124,  0.0122,  0.0121,  0.0123,\n           0.0122,  0.0123,  0.0121,  0.0122,  0.0123,  0.0121,  0.0122,  0.0121,\n           0.0123,  0.0123,  0.0122,  0.0121,  0.0122,  0.0124,  0.0123,  0.0123,\n           0.0121,  0.0122,  0.0122,  0.0121,  0.0122,  0.0123,  0.0123,  0.0123,\n           0.0121,  0.0122,  0.0121,  0.0122,  0.0122,  0.0123,  0.0122,  0.0122,\n           0.0123,  0.0124,  0.0123,  0.0124,  0.0122,  0.0123,  0.0122,  0.0125,\n           0.0122,  0.0122,  0.0123,  0.0123,  0.0123,  0.0124, -0.0635,  0.0036,\n           0.0037,  0.0034,  0.0036,  0.0036,  0.0037,  0.0036,  0.0036,  0.0037,\n           0.0035,  0.0036,  0.0035,  0.0035,  0.0037,  0.0035,  0.0037,  0.0035,\n           0.0037,  0.0035,  0.0036,  0.0037,  0.0037,  0.0036,  0.0035,  0.0036,\n           0.0035,  0.0035,  0.0036,  0.0037,  0.0036,  0.0033,  0.0036,  0.0035,\n           0.0035,  0.0035,  0.0036,  0.0037,  0.0036,  0.0036,  0.0035,  0.0037,\n           0.0036,  0.0037,  0.0036,  0.0037,  0.0037,  0.0036,  0.0036,  0.0036,\n           0.0035,  0.0035,  0.0035,  0.0036,  0.0034,  0.0036,  0.0036,  0.0037,\n           0.0072, -0.0138, -0.0138, -0.0138, -0.0141, -0.0137, -0.0137, -0.0138,\n          -0.0137, -0.0137, -0.0139, -0.0137, -0.0138, -0.0136, -0.0138, -0.0137,\n          -0.0139, -0.0138, -0.0137, -0.0139, -0.0137, -0.0139, -0.0138, -0.0139,\n          -0.0138, -0.0137, -0.0137, -0.0137, -0.0137, -0.0137, -0.0139, -0.0137,\n          -0.0138, -0.0137, -0.0138, -0.0137, -0.0138, -0.0137, -0.0138, -0.0138,\n          -0.0138, -0.0138, -0.0138, -0.0138, -0.0138, -0.0138, -0.0138, -0.0139,\n          -0.0137, -0.0138, -0.0137, -0.0135, -0.0138, -0.0138, -0.0136, -0.0138,\n          -0.0137, -0.0138,  0.1643,  0.1233,  0.1232,  0.1232,  0.1233,  0.1232,\n           0.1235,  0.1233,  0.1232,  0.1232,  0.1232,  0.1231,  0.1232,  0.1233,\n           0.1233,  0.1231,  0.1232,  0.1232,  0.1233,  0.1234,  0.1232,  0.1233,\n           0.1233,  0.1232,  0.1233,  0.1233,  0.1233,  0.1232,  0.1233,  0.1232,\n           0.1234,  0.1233,  0.1233,  0.1232,  0.1233,  0.1235,  0.1233,  0.1233,\n           0.1233,  0.1233,  0.1233,  0.1232,  0.1233,  0.1232,  0.1233,  0.1233,\n           0.1233,  0.1232,  0.1232,  0.1232,  0.1232,  0.1231,  0.1233,  0.1232,\n           0.1233,  0.1233,  0.1233,  0.1234,  0.0551, -0.0126, -0.0125, -0.0126,\n          -0.0125, -0.0125, -0.0125, -0.0126, -0.0125, -0.0125, -0.0126, -0.0126,\n          -0.0124, -0.0126, -0.0125, -0.0127, -0.0126, -0.0127, -0.0125, -0.0126,\n          -0.0126, -0.0126, -0.0124, -0.0126, -0.0126, -0.0125, -0.0126, -0.0127,\n          -0.0127, -0.0125, -0.0126, -0.0124, -0.0125, -0.0125, -0.0126, -0.0128,\n          -0.0126, -0.0125, -0.0126, -0.0125, -0.0125, -0.0126, -0.0124, -0.0126,\n          -0.0126, -0.0126, -0.0128, -0.0127, -0.0127, -0.0125, -0.0127, -0.0126,\n          -0.0126, -0.0126, -0.0125, -0.0126, -0.0125, -0.0127]],\n        grad_fn=<SqueezeBackward1>),\n tensor([[-0.0269, -0.0268, -0.0269, -0.0269, -0.0269, -0.0268, -0.0269, -0.0270,\n          -0.0269, -0.0268, -0.0269, -0.0268, -0.0269, -0.0270, -0.0268, -0.0269,\n          -0.0269, -0.0269, -0.0269, -0.0269, -0.0268, -0.0268, -0.0268, -0.0270,\n          -0.0269, -0.0269, -0.0269, -0.0268, -0.0268, -0.0267, -0.0268, -0.0270,\n          -0.0270, -0.0270, -0.0268, -0.0269, -0.0269, -0.0268, -0.0269, -0.0270,\n          -0.0271, -0.0270, -0.0268, -0.0270, -0.0269, -0.0269, -0.0270, -0.0269,\n          -0.0270, -0.0268, -0.0269, -0.0269, -0.0269, -0.0270, -0.0268, -0.0269,\n          -0.0268, -0.0946,  0.0900,  0.0901,  0.0900,  0.0902,  0.0901,  0.0900,\n           0.0901,  0.0900,  0.0901,  0.0900,  0.0900,  0.0901,  0.0901,  0.0901,\n           0.0901,  0.0900,  0.0902,  0.0901,  0.0900,  0.0901,  0.0900,  0.0901,\n           0.0899,  0.0901,  0.0901,  0.0900,  0.0900,  0.0901,  0.0901,  0.0901,\n           0.0901,  0.0900,  0.0901,  0.0901,  0.0902,  0.0900,  0.0900,  0.0901,\n           0.0899,  0.0901,  0.0901,  0.0899,  0.0901,  0.0900,  0.0902,  0.0901,\n           0.0902,  0.0902,  0.0900,  0.0901,  0.0900,  0.0901,  0.0900,  0.0901,\n           0.0900,  0.0900,  0.0900,  0.0757,  0.0226,  0.0226,  0.0226,  0.0225,\n           0.0226,  0.0226,  0.0225,  0.0227,  0.0225,  0.0226,  0.0224,  0.0225,\n           0.0226,  0.0225,  0.0225,  0.0226,  0.0225,  0.0226,  0.0226,  0.0225,\n           0.0226,  0.0226,  0.0225,  0.0223,  0.0226,  0.0226,  0.0225,  0.0226,\n           0.0226,  0.0225,  0.0226,  0.0225,  0.0224,  0.0225,  0.0225,  0.0225,\n           0.0225,  0.0226,  0.0224,  0.0224,  0.0225,  0.0224,  0.0227,  0.0225,\n           0.0223,  0.0226,  0.0225,  0.0225,  0.0226,  0.0225,  0.0224,  0.0224,\n           0.0225,  0.0225,  0.0225,  0.0224,  0.0226,  0.0410, -0.0919, -0.0918,\n          -0.0918, -0.0918, -0.0918, -0.0919, -0.0919, -0.0920, -0.0917, -0.0919,\n          -0.0918, -0.0918, -0.0918, -0.0919, -0.0917, -0.0919, -0.0918, -0.0920,\n          -0.0919, -0.0919, -0.0919, -0.0920, -0.0919, -0.0918, -0.0919, -0.0917,\n          -0.0920, -0.0918, -0.0917, -0.0920, -0.0918, -0.0919, -0.0917, -0.0919,\n          -0.0918, -0.0919, -0.0920, -0.0919, -0.0917, -0.0919, -0.0919, -0.0917,\n          -0.0919, -0.0917, -0.0919, -0.0918, -0.0918, -0.0917, -0.0916, -0.0918,\n          -0.0918, -0.0919, -0.0919, -0.0920, -0.0918, -0.0919, -0.0919, -0.2203,\n          -0.0140, -0.0139, -0.0141, -0.0141, -0.0139, -0.0140, -0.0139, -0.0140,\n          -0.0140, -0.0141, -0.0140, -0.0140, -0.0140, -0.0139, -0.0140, -0.0140,\n          -0.0140, -0.0140, -0.0139, -0.0139, -0.0139, -0.0139, -0.0139, -0.0139,\n          -0.0140, -0.0139, -0.0139, -0.0139, -0.0141, -0.0139, -0.0139, -0.0140,\n          -0.0140, -0.0139, -0.0139, -0.0140, -0.0141, -0.0139, -0.0141, -0.0140,\n          -0.0139, -0.0139, -0.0140, -0.0140, -0.0139, -0.0140, -0.0141, -0.0140,\n          -0.0140, -0.0140, -0.0139, -0.0140, -0.0139, -0.0140, -0.0140, -0.0139,\n          -0.0140,  0.0760,  0.0446,  0.0445,  0.0444,  0.0445,  0.0446,  0.0445,\n           0.0446,  0.0446,  0.0446,  0.0445,  0.0445,  0.0445,  0.0446,  0.0445,\n           0.0444,  0.0445,  0.0446,  0.0444,  0.0445,  0.0445,  0.0446,  0.0445,\n           0.0445,  0.0445,  0.0446,  0.0444,  0.0447,  0.0444,  0.0445,  0.0445,\n           0.0445,  0.0446,  0.0446,  0.0445,  0.0446,  0.0445,  0.0445,  0.0447,\n           0.0445,  0.0445,  0.0445,  0.0445,  0.0446,  0.0445,  0.0445,  0.0446,\n           0.0445,  0.0445,  0.0445,  0.0445,  0.0446,  0.0445,  0.0445,  0.0446,\n           0.0445,  0.0447,  0.0445,  0.0019,  0.0017,  0.0016,  0.0016,  0.0018,\n           0.0017,  0.0017,  0.0018,  0.0017,  0.0017,  0.0016,  0.0019,  0.0018,\n           0.0018,  0.0018,  0.0018,  0.0016,  0.0018,  0.0017,  0.0018,  0.0019,\n           0.0018,  0.0017,  0.0017,  0.0017,  0.0017,  0.0017,  0.0018,  0.0018,\n           0.0017,  0.0017,  0.0017,  0.0018,  0.0018,  0.0018,  0.0018,  0.0017,\n           0.0016,  0.0017,  0.0017,  0.0019,  0.0016,  0.0018,  0.0018,  0.0017,\n           0.0018,  0.0016,  0.0018,  0.0017,  0.0018,  0.0018,  0.0016,  0.0018,\n           0.0017,  0.0017,  0.0019,  0.0016,  0.0075,  0.0585,  0.0586,  0.0585,\n           0.0587,  0.0587,  0.0585,  0.0585,  0.0586,  0.0585,  0.0586,  0.0585,\n           0.0586,  0.0586,  0.0586,  0.0585,  0.0587,  0.0585,  0.0586,  0.0586,\n           0.0586,  0.0586,  0.0586,  0.0587,  0.0584,  0.0585,  0.0585,  0.0585,\n           0.0584,  0.0585,  0.0586,  0.0585,  0.0585,  0.0585,  0.0585,  0.0586,\n           0.0585,  0.0585,  0.0586,  0.0587,  0.0586,  0.0586,  0.0586,  0.0585,\n           0.0586,  0.0585,  0.0586,  0.0586,  0.0585,  0.0586,  0.0585,  0.0585,\n           0.0586,  0.0585,  0.0586,  0.0585,  0.0586,  0.0586,  0.0392, -0.0556,\n          -0.0558, -0.0555, -0.0555, -0.0557, -0.0557, -0.0554, -0.0556, -0.0557,\n          -0.0555, -0.0556, -0.0557, -0.0555, -0.0557, -0.0556, -0.0555, -0.0556,\n          -0.0557, -0.0555, -0.0555, -0.0556, -0.0556, -0.0557, -0.0555, -0.0553,\n          -0.0555, -0.0556, -0.0556, -0.0556, -0.0555, -0.0556, -0.0556, -0.0555,\n          -0.0555, -0.0557, -0.0555, -0.0555, -0.0555, -0.0555, -0.0556, -0.0557,\n          -0.0555, -0.0556, -0.0556, -0.0557, -0.0556, -0.0557, -0.0556, -0.0558,\n          -0.0556, -0.0556, -0.0554, -0.0557, -0.0557, -0.0556, -0.0555, -0.0557,\n           0.0379,  0.1309,  0.1308,  0.1308,  0.1309,  0.1308,  0.1308,  0.1308,\n           0.1309,  0.1308,  0.1307,  0.1308,  0.1308,  0.1309,  0.1309,  0.1308,\n           0.1309,  0.1310,  0.1309,  0.1308,  0.1309,  0.1307,  0.1310,  0.1309,\n           0.1309,  0.1309,  0.1308,  0.1308,  0.1309,  0.1309,  0.1308,  0.1308,\n           0.1308,  0.1307,  0.1308,  0.1308,  0.1310,  0.1309,  0.1309,  0.1307,\n           0.1308,  0.1308,  0.1307,  0.1307,  0.1308,  0.1308,  0.1309,  0.1308,\n           0.1308,  0.1308,  0.1309,  0.1310,  0.1309,  0.1309,  0.1308,  0.1308,\n           0.1308,  0.1309, -0.0315, -0.0663, -0.0663, -0.0662, -0.0664, -0.0664,\n          -0.0664, -0.0663, -0.0663, -0.0663, -0.0664, -0.0663, -0.0664, -0.0663,\n          -0.0664, -0.0663, -0.0664, -0.0662, -0.0664, -0.0662, -0.0664, -0.0663,\n          -0.0662, -0.0663, -0.0664, -0.0662, -0.0663, -0.0663, -0.0664, -0.0664,\n          -0.0663, -0.0663, -0.0665, -0.0662, -0.0664, -0.0663, -0.0662, -0.0664,\n          -0.0663, -0.0662, -0.0662, -0.0663, -0.0663, -0.0663, -0.0663, -0.0663,\n          -0.0664, -0.0663, -0.0661, -0.0662, -0.0661, -0.0664, -0.0663, -0.0663,\n          -0.0664, -0.0663, -0.0662, -0.0663, -0.1650, -0.1216, -0.1212, -0.1215,\n          -0.1215, -0.1213, -0.1215, -0.1214, -0.1214, -0.1215, -0.1214, -0.1213,\n          -0.1216, -0.1215, -0.1214, -0.1215, -0.1214, -0.1215, -0.1214, -0.1215,\n          -0.1213, -0.1213, -0.1215, -0.1214, -0.1215, -0.1216, -0.1215, -0.1215,\n          -0.1215, -0.1215, -0.1215, -0.1215, -0.1215, -0.1215, -0.1213, -0.1214,\n          -0.1213, -0.1215, -0.1215, -0.1215, -0.1216, -0.1215, -0.1215, -0.1214,\n          -0.1214, -0.1215, -0.1214, -0.1215, -0.1215, -0.1216, -0.1215, -0.1215,\n          -0.1215, -0.1215, -0.1214, -0.1215, -0.1214, -0.1214]],\n        grad_fn=<SqueezeBackward1>))"},"metadata":{}}],"execution_count":91},{"cell_type":"code","source":"start_positions = torch.argmax(start_logits, dim=-1)\nend_positions = torch.argmax(end_logits, dim=-1)\nstart_positions,end_positions","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:14:30.008095Z","iopub.execute_input":"2024-11-20T09:14:30.008476Z","iopub.status.idle":"2024-11-20T09:14:30.017697Z","shell.execute_reply.started":"2024-11-20T09:14:30.008444Z","shell.execute_reply":"2024-11-20T09:14:30.016613Z"},"trusted":true},"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"(tensor([98]), tensor([537]))"},"metadata":{}}],"execution_count":92},{"cell_type":"code","source":"output1=TOKEN_IDS[0][14:58]","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:13:30.738339Z","iopub.execute_input":"2024-11-20T09:13:30.738723Z","iopub.status.idle":"2024-11-20T09:13:30.744033Z","shell.execute_reply.started":"2024-11-20T09:13:30.738689Z","shell.execute_reply":"2024-11-20T09:13:30.742914Z"},"trusted":true},"outputs":[],"execution_count":80},{"cell_type":"code","source":"for idx in range(1):\n    start_idx=start_positions[idx]\n    end_idx=end_positions[idx]\n    if start_idx > end_idx:\n        start_idx, end_idx = end_idx, start_idx\n    predicted_answer_tokens = TOKEN_IDS[idx][start_idx:end_idx + 1]\n    predicted_answer = tokenizer.decode(predicted_answer_tokens, skip_special_tokens=True)\n    print(\"Question: \",l[idx][0])\n    print(\"Predicted answer:\",predicted_answer)\n    print(len(predicted_answer.split(\" \")))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T09:14:32.163174Z","iopub.execute_input":"2024-11-20T09:14:32.163604Z","iopub.status.idle":"2024-11-20T09:14:32.177069Z","shell.execute_reply.started":"2024-11-20T09:14:32.163567Z","shell.execute_reply":"2024-11-20T09:14:32.175891Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Question:  'When did Beyonce start becoming popular?\nPredicted answer: father, mathew knowles, the group became one of the world's best - selling girl groups of all time. their hiatus saw the release of beyonce's debut album, dangerously in love ( 2003 ), which established her as a solo artist worldwide, earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \".\n65\n","output_type":"stream"}],"execution_count":93},{"cell_type":"markdown","source":"### QA Answering","metadata":{}},{"cell_type":"code","source":"from transformers import BertModel, BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = BertModel.from_pretrained('bert-base-uncased')\n\nquestion=\"What is Cybersecurity?\"\nanswer=\"Cybersecurity is the practice of protecting systems, networks, and programs from digital attacks, theft, or damage. These cyberattacks usually aim to access, alter, or destroy sensitive information, extort money, or disrupt normal business ope\"\n\nencoding = tokenizer.encode_plus(question,answer, add_special_tokens=True, return_tensors='pt')\n\ninput_ids = encoding['input_ids']\nattention_mask = encoding['attention_mask']\n\nwith torch.no_grad():\n    outputs = bert_model(input_ids, attention_mask=attention_mask)\n\n    hidden_states = outputs.last_hidden_state  \n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-14T14:51:30.123253Z","iopub.execute_input":"2024-11-14T14:51:30.123887Z","iopub.status.idle":"2024-11-14T14:51:30.587587Z","shell.execute_reply.started":"2024-11-14T14:51:30.123847Z","shell.execute_reply":"2024-11-14T14:51:30.586558Z"},"trusted":true},"outputs":[],"execution_count":50},{"cell_type":"code","source":"\noutput_embeddings = attention_layer(hidden_states)\n\nqa_head = QAHead(hidden_size)\nstart_logits, end_logits = qa_head(output_embeddings)\n\nprint(\"Start Logits Shape:\", start_logits.shape)\nprint(\"End Logits Shape:\", end_logits.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T14:37:11.913236Z","iopub.execute_input":"2024-11-14T14:37:11.914205Z","iopub.status.idle":"2024-11-14T14:37:11.932698Z","shell.execute_reply.started":"2024-11-14T14:37:11.914152Z","shell.execute_reply":"2024-11-14T14:37:11.931744Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nQueries Matrix:-  tensor([[[ 0.0184,  0.1611, -0.3836,  ...,  0.1292,  0.4669, -0.2030],\n         [-0.0058,  0.2297, -0.3609,  ...,  0.4139, -0.1394, -0.2541],\n         [ 0.4735,  0.3752, -0.1296,  ...,  0.1937,  0.0320, -0.2238],\n         ...,\n         [ 0.1912,  0.5141,  0.0985,  ...,  0.4373,  0.6104,  0.2989],\n         [ 0.0195,  0.0310, -0.3529,  ...,  0.2429,  0.5118, -0.0774],\n         [ 0.6381, -0.2803,  0.3057,  ..., -0.0850,  0.0414,  0.0916]]],\n       grad_fn=<ViewBackward0>)\nQueries Matrix Shape: torch.Size([1, 61, 768])\n\nKeys Matrix:-  tensor([[[ 0.1287,  0.2809, -0.3580,  ...,  0.3848, -0.7865, -0.5094],\n         [ 0.2947,  0.5971, -0.1008,  ..., -0.0371, -0.1447, -0.4061],\n         [-0.1096, -0.2498, -0.2423,  ..., -0.3773, -0.1692, -0.2863],\n         ...,\n         [-0.0065,  0.2280, -0.0071,  ...,  0.3097, -0.9183, -0.6319],\n         [ 0.6146,  0.2203, -0.0187,  ...,  0.5495, -0.6867, -0.5252],\n         [ 0.0040, -0.0214, -0.2281,  ..., -0.1594, -0.2313, -0.3072]]],\n       grad_fn=<ViewBackward0>)\nKeys Matrix Shape: torch.Size([1, 61, 768])\n\nValues Matrix:-  tensor([[[ 0.0942, -0.0749, -0.3071,  ..., -0.3361,  0.1234, -0.1651],\n         [ 0.9273,  0.0571, -0.4117,  ..., -0.5538,  0.1536,  0.1808],\n         [ 0.0418, -0.5182,  0.0291,  ...,  0.1400, -0.3462, -0.3162],\n         ...,\n         [-0.0685, -0.0022, -0.4991,  ...,  0.3692, -0.3234, -0.2575],\n         [-0.3423,  0.1467,  0.1620,  ..., -0.4792,  0.1282, -0.4733],\n         [-0.4262, -0.1236, -0.0996,  ..., -0.0458,  0.1532, -0.0971]]],\n       grad_fn=<ViewBackward0>)\nValues Matrix Shape: torch.Size([1, 61, 768])\nAttention scores shape:  torch.Size([1, 12, 61, 61])\nAttention score shape after softmax:  torch.Size([1, 12, 61, 61])\nStart Logits Shape: torch.Size([1, 61])\nEnd Logits Shape: torch.Size([1, 61])\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"start_logits, end_logits","metadata":{"execution":{"iopub.status.busy":"2024-11-14T14:37:14.684931Z","iopub.execute_input":"2024-11-14T14:37:14.685310Z","iopub.status.idle":"2024-11-14T14:37:14.694767Z","shell.execute_reply.started":"2024-11-14T14:37:14.685273Z","shell.execute_reply":"2024-11-14T14:37:14.693743Z"},"trusted":true},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"(tensor([[-0.1130, -0.1107, -0.1124, -0.1113, -0.1130, -0.1404, -0.1513, -0.1548,\n          -0.1522, -0.1521,  0.0556,  0.0391,  0.0387,  0.0387,  0.0395,  0.0049,\n          -0.0209, -0.0213, -0.0220, -0.0225, -0.0092, -0.0129, -0.0140, -0.0148,\n          -0.0153, -0.0275, -0.0342, -0.0337, -0.0349, -0.0322,  0.0173,  0.0541,\n           0.0569,  0.0553,  0.0550, -0.0461, -0.0779, -0.0786, -0.0773, -0.0784,\n          -0.0210, -0.0703, -0.0700, -0.0711, -0.0715, -0.0223,  0.0030,  0.0037,\n           0.0040,  0.0045, -0.0220,  0.0123,  0.0123,  0.0117,  0.0119,  0.0152,\n          -0.0525, -0.0536, -0.0538, -0.0553, -0.0545]],\n        grad_fn=<SqueezeBackward1>),\n tensor([[ 0.0662,  0.0644,  0.0671,  0.0652,  0.0666, -0.0640, -0.0458, -0.0466,\n          -0.0444, -0.0459,  0.0934,  0.1679,  0.1741,  0.1658,  0.1715,  0.0750,\n           0.0351,  0.0322,  0.0354,  0.0348,  0.0864,  0.0489,  0.0483,  0.0524,\n           0.0515,  0.0594,  0.0904,  0.0876,  0.0878,  0.0882,  0.0730,  0.0593,\n           0.0600,  0.0563,  0.0558, -0.0084, -0.0489, -0.0485, -0.0498, -0.0498,\n           0.0552,  0.1853,  0.1892,  0.1828,  0.1868,  0.0930, -0.0721, -0.0738,\n          -0.0694, -0.0736, -0.0345,  0.0810,  0.0796,  0.0816,  0.0814,  0.0792,\n           0.0541,  0.0602,  0.0590,  0.0595,  0.0594]],\n        grad_fn=<SqueezeBackward1>))"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# Find the index of the start and end token with the highest logits\nstart_idx = torch.argmax(start_logits, dim=-1).item()\nend_idx = torch.argmax(end_logits, dim=-1).item()\nstart_idx,end_idx","metadata":{"execution":{"iopub.status.busy":"2024-11-14T14:37:52.774500Z","iopub.execute_input":"2024-11-14T14:37:52.774892Z","iopub.status.idle":"2024-11-14T14:37:52.782761Z","shell.execute_reply.started":"2024-11-14T14:37:52.774856Z","shell.execute_reply":"2024-11-14T14:37:52.781814Z"},"trusted":true},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(32, 42)"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"# # Find the index of the start and end token with the highest logits\n# start_idx = torch.argmax(start_logits, dim=-1).item()\n# end_idx = torch.argmax(end_logits, dim=-1).item()\n\n# Ensure start_idx <= end_idx (sometimes due to noise, the start index could be after the end index)\nif start_idx > end_idx:\n    start_idx, end_idx = end_idx, start_idx\n\n# Decode the answer from the token indices\npredicted_answer_tokens = input_ids[0][start_idx:end_idx + 1]\npredicted_answer = tokenizer.decode(predicted_answer_tokens, skip_special_tokens=True)\n# print(\"Question:\",kk[0])\nprint(\"Predicted Answer:\", predicted_answer)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-14T14:38:10.321053Z","iopub.execute_input":"2024-11-14T14:38:10.321700Z","iopub.status.idle":"2024-11-14T14:38:10.328229Z","shell.execute_reply.started":"2024-11-14T14:38:10.321646Z","shell.execute_reply":"2024-11-14T14:38:10.327256Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Predicted Answer: . these cyberattacks usually aim to access,\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"print(input_ids)","metadata":{"execution":{"iopub.status.busy":"2024-11-14T14:38:17.770361Z","iopub.execute_input":"2024-11-14T14:38:17.771526Z","iopub.status.idle":"2024-11-14T14:38:17.777537Z","shell.execute_reply.started":"2024-11-14T14:38:17.771474Z","shell.execute_reply":"2024-11-14T14:38:17.776634Z"},"trusted":true},"outputs":[{"name":"stdout","text":"tensor([[  101,  2054,  2003, 16941,  3366, 10841, 15780,  1029,   102, 16941,\n          3366, 10841, 15780,  2003,  1996,  3218,  1997,  8650,  3001,  1010,\n          6125,  1010,  1998,  3454,  2013,  3617,  4491,  1010, 11933,  1010,\n          2030,  4053,  1012,  2122, 16941, 19321,  8684,  2015,  2788,  6614,\n          2000,  3229,  1010, 11477,  1010,  2030,  6033,  7591,  2592,  1010,\n          4654, 25485,  2769,  1010,  2030, 23217,  3671,  2449,  6728,  2063,\n           102]])\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"bert_model","metadata":{"execution":{"iopub.status.busy":"2024-11-14T14:38:21.397655Z","iopub.execute_input":"2024-11-14T14:38:21.398666Z","iopub.status.idle":"2024-11-14T14:38:21.408213Z","shell.execute_reply.started":"2024-11-14T14:38:21.398609Z","shell.execute_reply":"2024-11-14T14:38:21.407106Z"},"trusted":true},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"\" What the tokenizer.decode does? It decodes the embeddings into human readable text format\"","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:04:57.515070Z","iopub.execute_input":"2024-11-18T09:04:57.515908Z","iopub.status.idle":"2024-11-18T09:04:57.521478Z","shell.execute_reply.started":"2024-11-18T09:04:57.515866Z","shell.execute_reply":"2024-11-18T09:04:57.520591Z"},"trusted":true},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"' What the tokenizer.decode does? It decodes the embeddings into human readable text format'"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"token_ids = [10, 203, 203, 903, 2741, 11]  # Example token IDs\ndecoded_text = tokenizer.decode(token_ids, skip_special_tokens=True)\nprint(decoded_text)  # Output: \"This is a test\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SimpleTokenizer:\n    def __init__(self, vocab):\n        # Initialize with a vocabulary mapping token IDs to tokens\n        self.vocab = vocab\n    \n    def convert_ids_to_tokens(self, token_ids):\n        # Convert token IDs to their corresponding tokens\n        return [self.vocab.get(token_id, '[UNK]') for token_id in token_ids]\n\n    def convert_tokens_to_string(self, tokens):\n        # Join tokens into a single string with spaces and handle subwords\n        text = ' '.join(tokens)\n        text = text.replace(' ##', '')  # Remove space before subword tokens\n        text = text.replace('##', '')   # Remove subword markers\n        return text.strip()\n\n    def decode(self, token_ids, skip_special_tokens=True):\n        # Convert token IDs to tokens\n        tokens = self.convert_ids_to_tokens(token_ids)\n#         print(tokens)\n        # Optionally skip special tokens like [CLS], [SEP], etc.\n        if skip_special_tokens:\n            tokens = [token for token in tokens if not token.startswith('[') and not token.endswith(']')]\n\n        # Convert tokens to a readable string\n        decoded_string = self.convert_tokens_to_string(tokens)\n        return decoded_string\n\n# Example usage\nif __name__ == \"__main__\":\n    # Example vocabulary\n    vocab = vocab\n    tokenizer = SimpleTokenizer(vocab)\n    token_ids = [101, 2009, 2001, 1037, 2307, 2154, 22299, 102]  # Example token IDs\n    decoded_text = tokenizer.decode(token_ids)\n    print(decoded_text)  # Output: \"It was a great day playing\"\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:27:59.509820Z","iopub.execute_input":"2024-11-18T09:27:59.510909Z","iopub.status.idle":"2024-11-18T09:27:59.520953Z","shell.execute_reply.started":"2024-11-18T09:27:59.510850Z","shell.execute_reply":"2024-11-18T09:27:59.520001Z"},"trusted":true},"outputs":[{"name":"stdout","text":"it was a great dayturn\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"### eg\nfor i in range(3):\n    start=min(start_positions[i],end_positions[i])\n    end=max(start_positions[i],end_positions[i])\n    print(start,\" \",end)\n    token_ids=TOKEN_IDS[i][start:end]\n    print(token_ids)\n    print(\"length is \",len(token_ids))\n    \n    vocab = vocab\n    tokenizer1= SimpleTokenizer(vocab)\n    decoded_text=tokenizer1.decode(token_ids)\n    \n    print(\"Decoded sentence is \",decoded_text)\n    \n    print(\"Length of decoded text is \",len(decoded_text.split(\" \")))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:28:01.958824Z","iopub.execute_input":"2024-11-18T09:28:01.959203Z","iopub.status.idle":"2024-11-18T09:28:01.969721Z","shell.execute_reply.started":"2024-11-18T09:28:01.959168Z","shell.execute_reply":"2024-11-18T09:28:01.968831Z"},"trusted":true},"outputs":[{"name":"stdout","text":"tensor(21)   tensor(44)\n[ 1010  1998  3454  2013  3617  4491  1010 11933  1010  2030  4053  1012\n  2122 16941 19321  8684  2015  2788  6614  2000  3229  1010 11477]\nlength is  23\nDecoded sentence is  , and programs from digital attacks , theft , or damage . these cyberattacks usually aim to access , alter\nLength of decoded text is  20\ntensor(21)   tensor(48)\n[ 3426  7386  2000  1037  3274  1010  2897  1010  2030  8241  1012  2009\n  2003  2109  2011 17857  2000  8954  2951  1010  8645  2006  5198  1010\n  2030  4053  3001]\nlength is  27\nDecoded sentence is  cause harm to a computer , network , or server . it is used by attackers to steal data , spy on users , or damage systems\nLength of decoded text is  27\ntensor(21)   tensor(44)\n[11476 11422  2000  7577  3633  2046  8669  7591  2592  2107  2004  5310\n 18442  2015  1010 20786  2015  1010  2030  3361  4751  1012 13569]\nlength is  23\nDecoded sentence is  legitimate entities to trick individuals into revealing sensitive information such as usernames , passwords , or financial details . phi\nLength of decoded text is  20\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"vocab={}\nfor key, value in tokenizer.vocab.items():\n    vocab[value]=key\nprint(len(vocab))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:26:05.079942Z","iopub.execute_input":"2024-11-18T09:26:05.080923Z","iopub.status.idle":"2024-11-18T09:26:05.099807Z","shell.execute_reply.started":"2024-11-18T09:26:05.080865Z","shell.execute_reply":"2024-11-18T09:26:05.098828Z"},"trusted":true},"outputs":[{"name":"stdout","text":"30522\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"def get_start_indices(context, qa_pairs):\n    \"\"\"\n    Function to find the start index of each answer in the context.\n\n    :param context: The main context string.\n    :param qa_pairs: List of question-answer dictionaries containing answers.\n    :return: List of dictionaries with question, answer, and start index.\n    \"\"\"\n    result = []\n    for qa in qa_pairs:\n        answer_text = qa[\"answers\"][0][\"text\"]  \n        start_index = context.find(answer_text)\n        \n        if start_index == -1:\n\n            print(f\"Answer '{answer_text}' not found in context.\")\n        else:\n            result.append({\n                \"question\": qa[\"question\"],\n                \"answer\": answer_text,\n                \"start_index\": start_index\n            })\n    return result\n\n\ncontext = (\n    \"Artificial Intelligence (AI) has revolutionized nearly every sector, and cybersecurity is no exception. As cyber threats become \"\n    \"increasingly sophisticated, AI is transforming how both vendors and defenders approach these evolving challenges. I recently joined \"\n    \"Chief Technology Officer and AI visionary Benjamin Bohman for an episode of AI Insights: The Executive Brief where we covered the \"\n    \"profound impact of AI on cybersecurity, including its role in combating alert fatigue, streamlining behavioral analytics, and shaping \"\n    \"future defense mechanisms.\\n\\n\"\n    \"The Rise of AI in Cybersecurity\\n\\n\"\n    \"The rise of AI in cybersecurity isn’t a recent phenomenon. Behavioral analytics, a core AI capability, has been evolving since 2012. \"\n    \"Initially, AI's role focused on analyzing user behavior to detect anomalies, such as unusual login patterns or data transfers. Over the years, \"\n    \"this has expanded into machine learning and deep learning applications that are far more complex, using vast datasets to predict potential threats \"\n    \"and automate defenses.\\n\\n\"\n    \"But what’s really driving the conversation today is how rapidly AI is evolving. More than 80% of cybersecurity vendors are now integrating AI \"\n    \"into their systems, building out different models and leveraging tools like generative AI and OpenAI. These innovations help companies stay ahead \"\n    \"of the ever-growing cyber threat landscape.\\n\\n\"\n    \"AI vs. AI: The Cybersecurity Arms Race\\n\\n\"\n    \"The current cybersecurity environment can be described as \\\"Machine vs. Machine.\\\" Cybersecurity vendors are deploying AI-enabled defenses, but \"\n    \"cybercriminals are equally quick to embrace AI-driven attacks. This dynamic has turned the traditional “cat and mouse” game between attackers and \"\n    \"defenders into an AI arms race.\\n\\n\"\n    \"Both sides are leveraging AI to automate processes. Defenders use AI for threat detection, while attackers are developing automated tools to breach \"\n    \"defenses. The more sophisticated these systems become, the more critical it is to evolve detection and defense mechanisms. In this high-speed AI-fueled \"\n    \"battle, cybersecurity vendors are constantly refining their capabilities to stay one step ahead. The challenge is to deploy AI models that are resilient \"\n    \"and less susceptible to being compromised by adversaries.\\n\\n\"\n    \"AI's Achilles Heel: Lack of Guardrails\\n\\n\"\n    \"While AI offers enormous potential, it’s not without its risks. As companies increasingly rely on AI, one significant concern is the lack of \\\"guardrails\\\"—\"\n    \"or safeguards—built into these systems. Without proper oversight, AI can lead companies into dangerous territory. We’re moving at breakneck speeds with AI, \"\n    \"likened to “driving 200 mph with no seatbelts or guardrails.”\\n\\n\"\n    \"AI models, while highly efficient, are not foolproof. They can be “poisoned” by attackers who trick them into making incorrect decisions, or they can fail to \"\n    \"detect novel threats. As most cybersecurity vendors invest in AI, the rush to implement new technologies often prioritizes profit over safety, increasing the \"\n    \"likelihood of vulnerabilities.\\n\\n\"\n    \"Defense in Depth: Beyond AI\\n\\n\"\n    \"While AI plays a critical role in modern cybersecurity, it is not a complete solution. AI-based models can only do so much, and as these systems evolve, defenders \"\n    \"need strategies that can adapt when AI systems fall short. This is where approaches like Automated Moving Target Defense (AMTD) come into play.\\n\\n\"\n    \"AMTD essentially \\\"morphs\\\" the attack surface, creating an ever-shifting environment that makes it harder for attackers to gain a foothold. Think of it as a kaleidoscope \"\n    \"or funhouse mirror—by constantly changing the landscape, AMTD provides an additional layer of defense that complements traditional AI-based detection models.\\n\\n\"\n    \"A Practical Layer of Protection\\n\\n\"\n    \"The combination of AI and additional layers of defense is crucial as organizations increasingly turn to platformization—standardizing their cybersecurity tools on platforms \"\n    \"like Microsoft. With Microsoft’s E5 licensing, for example, companies can streamline their cybersecurity operations, integrating AI and analytics directly into their operating systems.\\n\\n\"\n    \"However, even with these “easy button” solutions, there is still a need for strategies that go beyond standard defenses to mitigate the risks of AI failure.\\n\\n\"\n    \"By adopting AMTD and other adaptive mechanisms, companies can build a robust security posture that doesn’t rely solely on AI but uses it as part of a larger, multi-layered strategy.\\n\\n\"\n    \"Don’t Miss the Webinar\\n\\n\"\n    \"To get a deeper dive into how AI is shaping the future of cybersecurity, both for vendors and defenders. The conversation explores real-world examples, discusses the risks \"\n    \"and rewards of AI in cybersecurity, and offers practical advice for how companies can integrate AI into their security strategies while ensuring they remain resilient in the face of evolving threats.\\n\\n\"\n    \"Stay ahead of the curve—listen in on-demand to learn how you can leverage AI while avoiding the common pitfalls, and how to adopt additional layers of defense to protect your organization from future threats.\"\n)\n\nqa_pairs = [\n    {\n        \"question\": 'Who did the author join for an episode of AI Insights: The Executive Brief?',\n        \"answers\": [{\"text\": 'Chief Technology Officer and AI visionary Benjamin Bohman '}]\n    },\n    {\n        \"question\":\"What is the current cybersecurity environment described as?\",\n        \"answers\":[{\"text\":\"Machine vs. Machine.\"}]\n    }\n]\n\nstart_indices = get_start_indices(context, qa_pairs)\nprint(start_indices)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-22T14:19:39.992874Z","iopub.execute_input":"2024-11-22T14:19:39.993366Z","iopub.status.idle":"2024-11-22T14:19:40.036998Z","shell.execute_reply.started":"2024-11-22T14:19:39.993318Z","shell.execute_reply":"2024-11-22T14:19:40.035889Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[{'question': 'Who did the author join for an episode of AI Insights: The Executive Brief?', 'answer': 'Chief Technology Officer and AI visionary Benjamin Bohman ', 'start_index': 260}, {'question': 'What is the current cybersecurity environment described as?', 'answer': 'Machine vs. Machine.', 'start_index': 1464}]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## FINETUNING BERT MODEL","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:46:37.954974Z","iopub.execute_input":"2024-11-23T13:46:37.955294Z","iopub.status.idle":"2024-11-23T13:46:39.024327Z","shell.execute_reply.started":"2024-11-23T13:46:37.955270Z","shell.execute_reply":"2024-11-23T13:46:39.023443Z"}},"outputs":[{"name":"stdout","text":"Sat Nov 23 13:46:38 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   34C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"with open(\"/kaggle/input/qadata/SavedQAData.json\",\"r\") as f:\n    j=json.load(f)\nj[\"data\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:08:30.012470Z","iopub.execute_input":"2024-11-23T14:08:30.012833Z","iopub.status.idle":"2024-11-23T14:08:30.101257Z","shell.execute_reply.started":"2024-11-23T14:08:30.012802Z","shell.execute_reply":"2024-11-23T14:08:30.100273Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"{'question': 'Who did the author join for an episode of AI Insights: The Executive Brief?',\n 'context': 'Artificial Intelligence (AI) has revolutionized nearly every sector, and cybersecurity is no exception. As cyber threats become increasingly sophisticated, AI is transforming how both vendors and defenders approach these evolving challenges. I recently joined Chief Technology Officer and AI visionary Benjamin Bohman for an episode of AI Insights: The Executive Brief where we covered the profound impact of AI on cybersecurity, including its role in combating alert fatigue, streamlining behavioral analytics, and shaping future defense mechanisms.  The Rise of AI in Cybersecurity  The rise of AI in cybersecurity isn’t a recent phenomenon. Behavioral analytics, a core AI capability, has been evolving since 2012. Initially, AI\\'s role focused on analyzing user behavior to detect anomalies, such as unusual login patterns or data transfers. Over the years, this has expanded into machine learning and deep learning applications that are far more complex, using vast datasets to predict potential threats and automate defenses.  But what’s really driving the conversation today is how rapidly AI is evolving. More than 80% of cybersecurity vendors are now integrating AI into their systems, building out different models and leveraging tools like generative AI and OpenAI. These innovations help companies stay ahead of the ever-growing cyber threat landscape.  AI vs. AI: The Cybersecurity Arms Race  The current cybersecurity environment can be described as \"Machine vs. Machine.\" Cybersecurity vendors are deploying AI-enabled defenses, but cybercriminals are equally quick to embrace AI-driven attacks. This dynamic has turned the traditional “cat and mouse” game between attackers and defenders into an AI arms race.  Both sides are leveraging AI to automate processes. Defenders use AI for threat detection, while attackers are developing automated tools to breach defenses. The more sophisticated these systems become, the more critical it is to evolve detection and defense mechanisms. In this high-speed AI-fueled battle, cybersecurity vendors are constantly refining their capabilities to stay one step ahead. The challenge is to deploy AI models that are resilient and less susceptible to being compromised by adversaries.  AI\\'s Achilles Heel: Lack of Guardrails  While AI offers enormous potential, it’s not without its risks. As companies increasingly rely on AI, one significant concern is the lack of \"guardrails\"—or safeguards—built into these systems. Without proper oversight, AI can lead companies into dangerous territory. We’re moving at breakneck speeds with AI, likened to “driving 200 mph with no seatbelts or guardrails.”  AI models, while highly efficient, are not foolproof. They can be “poisoned” by attackers who trick them into making incorrect decisions, or they can fail to detect novel threats. As most cybersecurity vendors invest in AI, the rush to implement new technologies often prioritizes profit over safety, increasing the likelihood of vulnerabilities.  Defense in Depth: Beyond AI  While AI plays a critical role in modern cybersecurity, it is not a complete solution. AI-based models can only do so much, and as these systems evolve, defenders need strategies that can adapt when AI systems fall short. This is where approaches like Automated Moving Target Defense (AMTD) come into play.  AMTD essentially \"morphs\" the attack surface, creating an ever-shifting environment that makes it harder for attackers to gain a foothold. Think of it as a kaleidoscope or funhouse mirror—by constantly changing the landscape, AMTD provides an additional layer of defense that complements traditional AI-based detection models.  A Practical Layer of Protection  The combination of AI and additional layers of defense is crucial as organizations increasingly turn to platformization—standardizing their cybersecurity tools on platforms like Microsoft. With Microsoft’s E5 licensing, for example, companies can streamline their cybersecurity operations, integrating AI and analytics directly into their operating systems.  However, even with these “easy button” solutions, there is still a need for strategies that go beyond standard defenses to mitigate the risks of AI failure.  By adopting AMTD and other adaptive mechanisms, companies can build a robust security posture that doesn’t rely solely on AI but uses it as part of a larger, multi-layered strategy.  Don’t Miss the Webinar  to get a deeper dive into how AI is shaping the future of cybersecurity, both for vendors and defenders. The conversation explores real-world examples, discusses the risks and rewards of AI in cybersecurity, and offers practical advice for how companies can integrate AI into their security strategies while ensuring they remain resilient in the face of evolving threats.  Stay ahead of the curve—listen in on-demand to learn how you can leverage AI while avoiding the common pitfalls, and how to adopt additional layers of defense to protect your organization from future threats.',\n 'answer': 'The author joined Benjamin Bohman, a Chief Technology Officer and AI visionary, for an episode of AI Insights: The Executive Brief, where they discussed AI’s transformative role in cybersecurity, focusing on its applications and challenges.',\n 'is_answerable': True}"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"train_contexts = [\n    \"Nokia C12 Android 12 (Go Edition) Smartphone, All-Day Battery, 4GB RAM (2GB RAM + 2GB Virtual RAM) + 64GB Capacity | Light Mint\",\n    \"Nokia G21 Android Smartphone, Dual SIM, 3-Day Battery Life, 6GB RAM + 128GB Storage, 50MP Triple AI Camera | Nordic Blue\",\n    \"realme narzo 50i Prime (Dark Blue 4GB RAM+64GB Storage) Octa-core Processor | 5000 mAh Battery\",\n    \"realme narzo N53 (Feather Gold, 4GB+64GB) 33W Segment Fastest Charging | Slimmest Phone in Segment | 90 Hz Smooth Display\",\n    \"realme narzo N55 (Prime Blue, 4GB+64GB) 33W Segment Fastest Charging | Super High-res 64MP Primary AI Camera\",\n    \"Redmi 9A Sport (Carbon Black, 2GB RAM, 32GB Storage) | 2GHz Octa-core Helio G25 Processor | 5000 mAh Battery\",\n    \"Redmi 11 Prime 5G (Thunder Black, 4GB RAM, 64GB Storage) | Prime Design | MTK Dimensity 700 | 50 MP Dual Cam | 5000mAh | 7 Band 5G\",\n    \"Redmi 12C (Royal Blue, 4GB RAM, 64GB Storage) | High Performance Mediatek Helio G85 | Big 17cm(6.71) HD+ Display with 5000mAh(typ) Battery\",\n    \"Redmi A1 (Light Green, 2GB RAM 32GB ROM) | Segment Best AI Dual Cam | 5000mAh Battery | Leather Texture Design | Android 12\",\n    \"Samsung Galaxy M04 Light Green, 4GB RAM, 64GB Storage | Upto 8GB RAM with RAM Plus | MediaTek Helio P35 Octa-core Processor | 5000 mAh Battery | 13MP Dual Camera\",\n    \"Samsung Galaxy M13 (Midnight Blue, 4GB, 64GB Storage) | 6000mAh Battery | Upto 8GB RAM with RAM Plus\",\n    \"Tecno Camon 20 (Serenity Blue, 8GB RAM,256GB Storage)|16GB Expandable RAM | 64MP RGBW Rear Camera|6.67 FHD+ Big AMOLED with in-Display Fingerprint Sensor\",\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:47:01.165633Z","iopub.execute_input":"2024-11-23T13:47:01.166018Z","iopub.status.idle":"2024-11-23T13:47:01.172519Z","shell.execute_reply.started":"2024-11-23T13:47:01.165984Z","shell.execute_reply":"2024-11-23T13:47:01.171496Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"len(train_contexts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:47:12.674270Z","iopub.execute_input":"2024-11-23T13:47:12.674965Z","iopub.status.idle":"2024-11-23T13:47:12.681523Z","shell.execute_reply.started":"2024-11-23T13:47:12.674932Z","shell.execute_reply":"2024-11-23T13:47:12.680681Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"12"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_questions_answers = [\n    {\n        \"context_index\": 0,\n        \"question\": \"What is the operating system of the Nokia C12 smartphone?\",\n        \"answer\": \"Android 12 (Go Edition)\"\n    },\n    {\n        \"context_index\": 0,\n        \"question\": \"How much RAM does the Nokia C12 have?\",\n        \"answer\": \"4GB\"\n    },\n    {\n        \"context_index\": 0,\n        \"question\": \"Does the Nokia C12 have virtual RAM?\",\n        \"answer\": \"(2GB RAM + 2GB Virtual RAM)\"\n    },\n    {\n        \"context_index\": 0,\n        \"question\": \"What is the total capacity of the Nokia C12?\",\n        \"answer\": \"64GB\"\n    },\n    {\n        \"context_index\": 0,\n        \"question\": \"What is the color option available for the Nokia C12?\",\n        \"answer\": \"Light Mint\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What is the model name of the Nokia smartphone?\",\n        \"answer\": \"Nokia G21\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What is the operating system of the Nokia G21?\",\n        \"answer\": \"Android\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"How many SIM cards does the Nokia G21 support?\",\n        \"answer\": \"Dual SIM\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"How long is the battery life of the Nokia G21?\",\n        \"answer\": \"3-Day Battery Life\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"How much RAM does the Nokia G21 have?\",\n        \"answer\": \"6GB\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What is the storage capacity of the Nokia G21?\",\n        \"answer\": \"128GB\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What is the resolution of the main camera on the Nokia G21?\",\n        \"answer\": \"50MP\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"How many AI cameras does the Nokia G21 have?\",\n        \"answer\": \"Triple AI Camera\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What is the color option available for the Nokia G21?\",\n        \"answer\": \"Nordic Blue\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"What is the model name of the Realme smartphone?\",\n        \"answer\": \"Realme narzo 50i Prime\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"What is the color option available for the Realme narzo 50i Prime?\",\n        \"answer\": \"Dark Blue\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"How much RAM does the Realme narzo 50i Prime have?\",\n        \"answer\": \"4GB\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"What is the storage capacity of the Realme narzo 50i Prime?\",\n        \"answer\": \"64GB\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"What type of processor does the Realme narzo 50i Prime have?\",\n        \"answer\": \"Octa-core Processor\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"What is the battery capacity of the Realme narzo 50i Prime?\",\n        \"answer\": \"5000 mAh\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the model name of the Realme smartphone?\",\n        \"answer\": \"Realme narzo N53\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the color option available for the Realme narzo N53?\",\n        \"answer\": \"Feather Gold\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"How much RAM does the Realme narzo N53 have?\",\n        \"answer\": \"4GB\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the storage capacity of the Realme narzo N53?\",\n        \"answer\": \"64GB\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the charging speed of the Realme narzo N53?\",\n        \"answer\": \"33W Segment Fastest Charging\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the special feature of the Realme narzo N53 in terms of phone thickness?\",\n        \"answer\": \"Slimmest Phone in Segment\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the refresh rate of the display on the Realme narzo N53?\",\n        \"answer\": \"90 Hz\"\n    },\n    {\n        \"context_index\": 4,\n        \"question\": \"What is the model name of the Realme smartphone?\",\n        \"answer\": \"Realme narzo N55\"\n    },\n    {\n        \"context_index\": 4,\n        \"question\": \"What is the color option available for the Realme narzo N55?\",\n        \"answer\": \"Prime Blue\"\n    },\n    {\n        \"context_index\": 4,\n        \"question\": \"How much RAM does the Realme narzo N55 have?\",\n        \"answer\": \"4GB\"\n    },\n    {\n        \"context_index\": 4,\n        \"question\": \"What is the storage capacity of the Realme narzo N55?\",\n        \"answer\": \"64GB\"\n    },\n    {\n        \"context_index\": 4,\n        \"question\": \"What is the charging speed of the Realme narzo N55?\",\n        \"answer\": \"33W Segment Fastest Charging\"\n    },\n    {\n        \"context_index\": 4,\n        \"question\": \"What is the resolution of the primary AI camera on the Realme narzo N55?\",\n        \"answer\": \"Super High-res 64MP\"\n    },\n    {\n        \"context_index\": 5,\n        \"question\": \"What is the model name of the Redmi smartphone?\",\n        \"answer\": \"Redmi 9A Sport\"\n    },\n    {\n        \"context_index\": 5,\n        \"question\": \"What is the color option available for the Redmi 9A Sport?\",\n        \"answer\": \"Carbon Black\"\n    },\n    {\n        \"context_index\": 5,\n        \"question\": \"How much RAM does the Redmi 9A Sport have?\",\n        \"answer\": \"2GB\"\n    },\n    {\n        \"context_index\": 5,\n        \"question\": \"What is the storage capacity of the Redmi 9A Sport?\",\n        \"answer\": \"32GB\"\n    },\n    {\n        \"context_index\": 5,\n        \"question\": \"What is the processor of the Redmi 9A Sport?\",\n        \"answer\": \"2GHz Octa-core Helio G25 Processor\"\n    },\n    {\n        \"context_index\": 5,\n        \"question\": \"What is the battery capacity of the Redmi 9A Sport?\",\n        \"answer\": \"5000 mAh\"\n    },\n    {\n        \"context_index\": 6,\n        \"question\": \"What is the model name of the Redmi smartphone?\",\n        \"answer\": \"Redmi 11 Prime 5G\"\n    },\n    {\n        \"context_index\": 6,\n        \"question\": \"What is the color option available for the Redmi 11 Prime 5G?\",\n        \"answer\": \"Thunder Black\"\n    },\n    {\n        \"context_index\": 6,\n        \"question\": \"How much RAM does the Redmi 11 Prime 5G have?\",\n        \"answer\": \"4GB\"\n    },\n    {\n        \"context_index\": 6,\n        \"question\": \"What is the storage capacity of the Redmi 11 Prime 5G?\",\n        \"answer\": \"64GB\"\n    },\n    {\n        \"context_index\": 6,\n        \"question\": \"What is the special feature of the Redmi 11 Prime 5G in terms of design?\",\n        \"answer\": \"Prime Design\"\n    },\n    {\n        \"context_index\": 6,\n        \"question\": \"What is the processor of the Redmi 11 Prime 5G?\",\n        \"answer\": \"MTK Dimensity 700\"\n    },\n    {\n        \"context_index\": 6,\n        \"question\": \"What is the resolution of the dual camera on the Redmi 11 Prime 5G?\",\n        \"answer\": \"50 MP\"\n    },\n    {\n        \"context_index\": 6,\n        \"question\": \"What is the battery capacity of the Redmi 11 Prime 5G?\",\n        \"answer\": \"5000mAh\"\n    },\n    {\n        \"context_index\": 6,\n        \"question\": \"How many 5G bands does the Redmi 11 Prime 5G support?\",\n        \"answer\": \"7 Band 5G\"\n    },\n    {\n        \"context_index\": 7,\n        \"question\": \"What is the model name of the Redmi smartphone?\",\n        \"answer\": \"Redmi 12C\"\n    },\n    {\n        \"context_index\": 7,\n        \"question\": \"What is the color option available for the Redmi 12C?\",\n        \"answer\": \"Royal Blue\"\n    },\n    {\n        \"context_index\": 7,\n        \"question\": \"How much RAM does the Redmi 12C have?\",\n        \"answer\": \"4GB\"\n    },\n    {\n        \"context_index\": 7,\n        \"question\": \"What is the storage capacity of the Redmi 12C?\",\n        \"answer\": \"64GB\"\n    },\n    {\n        \"context_index\": 7,\n        \"question\": \"What is the processor of the Redmi 12C?\",\n        \"answer\": \"High Performance Mediatek Helio G85\"\n    },\n    {\n        \"context_index\": 7,\n        \"question\": \"What is the size of the display on the Redmi 12C?\",\n        \"answer\": \"Big 17cm(6.71) HD+ Display\"\n    },\n    {\n        \"context_index\": 7,\n        \"question\": \"What is the battery capacity of the Redmi 12C?\",\n        \"answer\": \"5000mAh(typ) Battery\"\n    },\n    {\n        \"context_index\": 8,\n        \"question\": \"What is the model name of the Redmi smartphone?\",\n        \"answer\": \"Redmi A1\"\n    },\n    {\n        \"context_index\": 8,\n        \"question\": \"What is the color option available for the Redmi A1?\",\n        \"answer\": \"Light Green\"\n    },\n    {\n        \"context_index\": 8,\n        \"question\": \"How much RAM does the Redmi A1 have?\",\n        \"answer\": \"2GB\"\n    },\n    {\n        \"context_index\": 8,\n        \"question\": \"What is the storage capacity of the Redmi A1?\",\n        \"answer\": \"32GB\"\n    },\n    {\n        \"context_index\": 8,\n        \"question\": \"What is the special feature of the camera on the Redmi A1?\",\n        \"answer\": \"Segment Best AI Dual Cam\"\n    },\n    {\n        \"context_index\": 8,\n        \"question\": \"What is the battery capacity of the Redmi A1?\",\n        \"answer\": \"5000mAh Battery\"\n    },\n    {\n        \"context_index\": 8,\n        \"question\": \"What is the design feature of the Redmi A1?\",\n        \"answer\": \"Leather Texture Design\"\n    },\n    {\n        \"context_index\": 8,\n        \"question\": \"What is the operating system of the Redmi A1?\",\n        \"answer\": \"Android 12\"\n    },\n    {\n        \"context_index\": 9,\n        \"question\": \"What is the model name of the Samsung smartphone?\",\n        \"answer\": \"Samsung Galaxy M04\"\n    },\n    {\n        \"context_index\": 9,\n        \"question\": \"What is the color option available for the Samsung Galaxy M04?\",\n        \"answer\": \"Light Green\"\n    },\n    {\n        \"context_index\": 9,\n        \"question\": \"How much RAM does the Samsung Galaxy M04 have?\",\n        \"answer\": \"4GB\"\n    },\n    {\n        \"context_index\": 9,\n        \"question\": \"What is the storage capacity of the Samsung Galaxy M04?\",\n        \"answer\": \"64GB\"\n    },\n    {\n        \"context_index\": 9,\n        \"question\": \"How much RAM can the Samsung Galaxy M04 have with RAM Plus?\",\n        \"answer\": \"Upto 8GB RAM with RAM Plus\"\n    },\n    {\n        \"context_index\": 9,\n        \"question\": \"What is the processor of the Samsung Galaxy M04?\",\n        \"answer\": \"MediaTek Helio P35 Octa-core Processor\"\n    },\n    {\n        \"context_index\": 9,\n        \"question\": \"What is the battery capacity of the Samsung Galaxy M04?\",\n        \"answer\": \"5000 mAh\"\n    },\n    {\n        \"context_index\": 9,\n        \"question\": \"What is the resolution of the dual camera on the Samsung Galaxy M04?\",\n        \"answer\": \"13MP\"\n    },\n    {\n        \"context_index\": 10,\n        \"question\": \"What is the model name of the Samsung smartphone?\",\n        \"answer\": \"Samsung Galaxy M13\"\n    },\n    {\n        \"context_index\": 10,\n        \"question\": \"What is the color option available for the Samsung Galaxy M13?\",\n        \"answer\": \"Midnight Blue\"\n    },\n    {\n        \"context_index\": 10,\n        \"question\": \"How much RAM does the Samsung Galaxy M13 have?\",\n        \"answer\": \"4GB\"\n    },\n    {\n        \"context_index\": 10,\n        \"question\": \"What is the storage capacity of the Samsung Galaxy M13?\",\n        \"answer\": \"64GB\"\n    },\n    {\n        \"context_index\": 10,\n        \"question\": \"What is the battery capacity of the Samsung Galaxy M13?\",\n        \"answer\": \"6000mAh\"\n    },\n    {\n        \"context_index\": 10,\n        \"question\": \"How much RAM can the Samsung Galaxy M13 have with RAM Plus?\",\n        \"answer\": \"Upto 8GB RAM with RAM Plus\"\n    },\n    {\n        \"context_index\": 11,\n        \"question\": \"What is the model name of the Tecno smartphone?\",\n        \"answer\": \"Tecno Camon 20\"\n    },\n    {\n        \"context_index\": 11,\n        \"question\": \"What is the color option available for the Tecno Camon 20?\",\n        \"answer\": \"Serenity Blue\"\n    },\n    {\n        \"context_index\": 11,\n        \"question\": \"How much RAM does the Tecno Camon 20 have?\",\n        \"answer\": \"8GB\"\n    },\n    {\n        \"context_index\": 11,\n        \"question\": \"What is the storage capacity of the Tecno Camon 20?\",\n        \"answer\": \"256GB\"\n    },\n    {\n        \"context_index\": 11,\n        \"question\": \"How much expandable RAM can the Tecno Camon 20 have?\",\n        \"answer\": \"16GB\"\n    },\n    {\n        \"context_index\": 11,\n        \"question\": \"What is the resolution of the rear camera on the Tecno Camon 20?\",\n        \"answer\": \"64MP RGBW\"\n    },\n    {\n        \"context_index\": 11,\n        \"question\": \"What is the size of the display on the Tecno Camon 20?\",\n        \"answer\": \"6.67 FHD+\"\n    },\n    {\n        \"context_index\": 11,\n        \"question\": \"What type of display does the Tecno Camon 20 have?\",\n        \"answer\": \"Big AMOLED\"\n    },\n    {\n        \"context_index\": 11,\n        \"question\": \"What feature is integrated into the display of the Tecno Camon 20?\",\n        \"answer\": \"In-Display Fingerprint Sensor\"\n    }\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:47:54.045387Z","iopub.execute_input":"2024-11-23T13:47:54.045760Z","iopub.status.idle":"2024-11-23T13:47:54.066966Z","shell.execute_reply.started":"2024-11-23T13:47:54.045708Z","shell.execute_reply":"2024-11-23T13:47:54.066071Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_data = []\ntrain_contexts_data = []\n \nfor i, context in enumerate(train_contexts):\n    qas = []\n    for qa in train_questions_answers:\n        if qa[\"context_index\"] == i:\n            answer_start = context.find(qa[\"answer\"])\n            if answer_start != -1:\n                qas.append({\n                    \"id\": str(len(qas) + 1).zfill(5),\n                    \"is_impossible\": False,\n                    \"question\": qa[\"question\"],\n                    \"answers\": [\n                        {\n                            \"text\": qa[\"answer\"],\n                            \"answer_start\": answer_start,\n                        }\n                    ],\n                })\n    train_contexts_data.append({\n        \"context\": context,\n        \"qas\": qas,\n    })\n \ntrain_data.extend(train_contexts_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:48:06.089241Z","iopub.execute_input":"2024-11-23T13:48:06.089577Z","iopub.status.idle":"2024-11-23T13:48:06.095571Z","shell.execute_reply.started":"2024-11-23T13:48:06.089548Z","shell.execute_reply":"2024-11-23T13:48:06.094634Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_data[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:48:18.383631Z","iopub.execute_input":"2024-11-23T13:48:18.383989Z","iopub.status.idle":"2024-11-23T13:48:18.390520Z","shell.execute_reply.started":"2024-11-23T13:48:18.383959Z","shell.execute_reply":"2024-11-23T13:48:18.389711Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'context': 'Nokia C12 Android 12 (Go Edition) Smartphone, All-Day Battery, 4GB RAM (2GB RAM + 2GB Virtual RAM) + 64GB Capacity | Light Mint',\n 'qas': [{'id': '00001',\n   'is_impossible': False,\n   'question': 'What is the operating system of the Nokia C12 smartphone?',\n   'answers': [{'text': 'Android 12 (Go Edition)', 'answer_start': 10}]},\n  {'id': '00002',\n   'is_impossible': False,\n   'question': 'How much RAM does the Nokia C12 have?',\n   'answers': [{'text': '4GB', 'answer_start': 63}]},\n  {'id': '00003',\n   'is_impossible': False,\n   'question': 'Does the Nokia C12 have virtual RAM?',\n   'answers': [{'text': '(2GB RAM + 2GB Virtual RAM)', 'answer_start': 71}]},\n  {'id': '00004',\n   'is_impossible': False,\n   'question': 'What is the total capacity of the Nokia C12?',\n   'answers': [{'text': '64GB', 'answer_start': 101}]},\n  {'id': '00005',\n   'is_impossible': False,\n   'question': 'What is the color option available for the Nokia C12?',\n   'answers': [{'text': 'Light Mint', 'answer_start': 117}]}]}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import json\n \nwith open('amazon_data_train.json', 'w', encoding='utf-8') as f:\n    json.dump(train_data, f, ensure_ascii=False, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T13:48:32.545827Z","iopub.execute_input":"2024-11-23T13:48:32.546604Z","iopub.status.idle":"2024-11-23T13:48:32.553202Z","shell.execute_reply.started":"2024-11-23T13:48:32.546573Z","shell.execute_reply":"2024-11-23T13:48:32.552443Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"test_contexts = [\n    \"Redmi Note 11 (Space Black, 4GB RAM, 64GB Storage)|90Hz FHD+ AMOLED Display | Qualcomm® Snapdragon™ 680-6nm | 33W Charger Included\",\n    \"Redmi Note 10S (Deep Sea Blue, 6GB RAM, 64GB Storage) - Super Amoled Display | 64 MP Quad Camera | 6 Month Free Screen Replacement (Prime only) |33W Charger Included\",\n    \"Lava Blaze 5G (Glass Green, 6GB RAM, UFS 2.2 128GB Storage) | 5G Ready | 50MP AI Triple Camera | Upto 11GB Expandable RAM | Charger Included | Clean Android (No Bloatware)\",\n    \"Oppo A78 5G (Glowing Black, 8GB RAM, 128 Storage) | 5000 mAh Battery with 33W SUPERVOOC Charger| 50MP AI Camera | 90Hz Refresh Rate | with No Cost EMI/Additional Exchange Offers\"\n]\n \ntest_questions_answers = [\n    {\n        \"context_index\": 0,\n        \"question\": \"What is the model name of the Redmi smartphone?\",\n        \"answer\": \"Redmi Note 11\"\n    },\n    {\n        \"context_index\": 0,\n        \"question\": \"What is the color option available for the Redmi Note 11?\",\n        \"answer\": \"Space Black\"\n    },\n    {\n        \"context_index\": 0,\n        \"question\": \"How much RAM does the Redmi Note 11 have?\",\n        \"answer\": \"4GB\"\n    },\n    {\n        \"context_index\": 0,\n        \"question\": \"What is the storage capacity of the Redmi Note 11?\",\n        \"answer\": \"64GB\"\n    },\n    {\n        \"context_index\": 0,\n        \"question\": \"What is the display feature of the Redmi Note 11?\",\n        \"answer\": \"90Hz FHD+ AMOLED Display\"\n    },\n    {\n        \"context_index\": 0,\n        \"question\": \"What is the processor of the Redmi Note 11?\",\n        \"answer\": \"Qualcomm Snapdragon 680-6nm\"\n    },\n    {\n        \"context_index\": 0,\n        \"question\": \"What is included in the package of the Redmi Note 11?\",\n        \"answer\": \"33W Charger Included\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What is the model name of the Redmi smartphone?\",\n        \"answer\": \"Redmi Note 10S\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What is the color option available for the Redmi Note 10S?\",\n        \"answer\": \"Deep Sea Blue\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"How much RAM does the Redmi Note 10S have?\",\n        \"answer\": \"6GB\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What is the storage capacity of the Redmi Note 10S?\",\n        \"answer\": \"64GB\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What type of display does the Redmi Note 10S have?\",\n        \"answer\": \"Super Amoled Display\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What is the resolution of the camera on the Redmi Note 10S?\",\n        \"answer\": \"64 MP Quad Camera\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What is the special offer for screen replacement on the Redmi Note 10S?\",\n        \"answer\": \"6 Month Free Screen Replacement (Prime only)\"\n    },\n    {\n        \"context_index\": 1,\n        \"question\": \"What is included in the package of the Redmi Note 10S?\",\n        \"answer\": \"33W Charger Included\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"What is the model name of the Lava smartphone?\",\n        \"answer\": \"Lava Blaze 5G\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"What is the color option available for the Lava Blaze 5G?\",\n        \"answer\": \"Glass Green\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"How much RAM does the Lava Blaze 5G have?\",\n        \"answer\": \"6GB\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"What is the storage capacity of the Lava Blaze 5G?\",\n        \"answer\": \"UFS 2.2 128GB\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"Is the Lava Blaze 5G compatible with 5G networks?\",\n        \"answer\": \"5G Ready\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"What is the resolution of the camera on the Lava Blaze 5G?\",\n        \"answer\": \"50MP AI Triple Camera\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"How much expandable RAM does the Lava Blaze 5G support?\",\n        \"answer\": \"Upto 11GB Expandable RAM\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"What is included in the package of the Lava Blaze 5G?\",\n        \"answer\": \"Charger Included\"\n    },\n    {\n        \"context_index\": 2,\n        \"question\": \"What operating system does the Lava Blaze 5G use?\",\n        \"answer\": \"Clean Android (No Bloatware)\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the model name of the Oppo smartphone?\",\n        \"answer\": \"Oppo A78 5G\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the color option available for the Oppo A78 5G?\",\n        \"answer\": \"Glowing Black\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"How much RAM does the Oppo A78 5G have?\",\n        \"answer\": \"8GB\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the storage capacity of the Oppo A78 5G?\",\n        \"answer\": \"128GB\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the battery capacity of the Oppo A78 5G?\",\n        \"answer\": \"5000 mAh\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the charging speed of the Oppo A78 5G?\",\n        \"answer\": \"33W SUPERVOOC Charger\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the resolution of the camera on the Oppo A78 5G?\",\n        \"answer\": \"50MP AI Camera\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"What is the refresh rate of the display on the Oppo A78 5G?\",\n        \"answer\": \"90Hz Refresh Rate\"\n    },\n    {\n        \"context_index\": 3,\n        \"question\": \"Are there any additional offers available for the Oppo A78 5G?\",\n        \"answer\": \"with No Cost EMI/Additional Exchange Offers\"\n    }\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:12:32.702135Z","iopub.execute_input":"2024-11-23T16:12:32.702518Z","iopub.status.idle":"2024-11-23T16:12:32.712881Z","shell.execute_reply.started":"2024-11-23T16:12:32.702489Z","shell.execute_reply":"2024-11-23T16:12:32.712006Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"test_data = []\ntest_contexts_data = []\n \nfor i, context in enumerate(test_contexts):\n    qas = []\n    for qa in test_questions_answers:\n        if qa[\"context_index\"] == i:\n            answer_start = context.find(qa[\"answer\"])\n            if answer_start != -1:\n                qas.append({\n                    \"id\": str(len(qas) + 1).zfill(5),\n                    \"is_impossible\": False,\n                    \"question\": qa[\"question\"],\n                    \"answers\": [\n                        {\n                            \"text\": qa[\"answer\"],\n                            \"answer_start\": answer_start,\n                        }\n                    ],\n                })\n    test_contexts_data.append({\n        \"context\": context,\n        \"qas\": qas,\n    })\n \ntest_data.extend(test_contexts_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:12:42.767045Z","iopub.execute_input":"2024-11-23T16:12:42.767838Z","iopub.status.idle":"2024-11-23T16:12:42.773355Z","shell.execute_reply.started":"2024-11-23T16:12:42.767805Z","shell.execute_reply":"2024-11-23T16:12:42.772411Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\nwith open('amazon_data_test.json', 'w', encoding='utf-8') as f:\n    json.dump(test_data, f, ensure_ascii=False, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:12:46.481544Z","iopub.execute_input":"2024-11-23T16:12:46.482254Z","iopub.status.idle":"2024-11-23T16:12:46.487239Z","shell.execute_reply.started":"2024-11-23T16:12:46.482220Z","shell.execute_reply":"2024-11-23T16:12:46.486424Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import json\n\nwith open(r\"/kaggle/input/new-dataset/new_train_JSON_Data.json\", \"r\") as read_file:\n    train = json.load(read_file)\n \nwith open(r\"/kaggle/working/amazon_data_test.json\", \"r\") as read_file:\n    test = json.load(read_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:13:26.134552Z","iopub.execute_input":"2024-11-23T16:13:26.135277Z","iopub.status.idle":"2024-11-23T16:13:26.142049Z","shell.execute_reply.started":"2024-11-23T16:13:26.135244Z","shell.execute_reply":"2024-11-23T16:13:26.141351Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:13:29.192008Z","iopub.execute_input":"2024-11-23T16:13:29.192820Z","iopub.status.idle":"2024-11-23T16:13:29.201515Z","shell.execute_reply.started":"2024-11-23T16:13:29.192786Z","shell.execute_reply":"2024-11-23T16:13:29.200581Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'context': 'AI has been transforming cybersecurity since 2012, initially through behavioral analytics to detect anomalies like unusual logins or data transfers. Over time, its role expanded to advanced machine learning and deep learning, enabling predictive threat detection and automated defense mechanisms. Today, over 80% of cybersecurity vendors incorporate AI, leveraging tools like generative AI to stay ahead of an ever-evolving threat landscape.',\n 'qas': [{'id': '0',\n   'question': 'When did AI begin transforming cybersecurity?',\n   'answer': [{'text': '', 'answer_start': 0}],\n   'is_impossible': True},\n  {'id': '1',\n   'question': 'What was the initial role of AI in cybersecurity?',\n   'answer': [{'text': 'behavioral analytics to detect anomalies like unusual logins or data transfers',\n     'answer_start': 69}],\n   'is_impossible': True},\n  {'id': '2',\n   'question': 'What are examples of anomalies detected by AI in its initial role?',\n   'answer': [{'text': 'unusual logins or data transfers',\n     'answer_start': 115}],\n   'is_impossible': True},\n  {'id': '3',\n   'question': 'How has the role of AI in cybersecurity expanded over time?',\n   'answer': [{'text': 'advanced machine learning and deep learning, enabling predictive threat detection and automated defense mechanisms',\n     'answer_start': 90}],\n   'is_impossible': True},\n  {'id': '4',\n   'question': 'What technologies enable predictive threat detection and automated defense mechanisms?',\n   'answer': [{'text': 'advanced machine learning and deep learning',\n     'answer_start': 181}],\n   'is_impossible': True},\n  {'id': '5',\n   'question': 'What percentage of cybersecurity vendors incorporate AI today?',\n   'answer': [{'text': 'over 80%', 'answer_start': 149}],\n   'is_impossible': True},\n  {'id': '6',\n   'question': 'What do cybersecurity vendors use AI tools for?',\n   'answer': [{'text': 'leveraging tools like generative AI to stay ahead of an ever-evolving threat landscape',\n     'answer_start': 410}],\n   'is_impossible': True},\n  {'id': '7',\n   'question': 'What is one specific type of AI tool mentioned in the context?',\n   'answer': [{'text': 'generative AI', 'answer_start': 376}],\n   'is_impossible': True},\n  {'id': '8',\n   'question': 'What type of threat landscape do cybersecurity vendors face?',\n   'answer': [{'text': 'an ever-evolving threat landscape',\n     'answer_start': 246}],\n   'is_impossible': True},\n  {'id': '9',\n   'question': 'What was the purpose of behavioral analytics in AI’s initial role?',\n   'answer': [{'text': 'to detect anomalies like unusual logins or data transfers',\n     'answer_start': 100}],\n   'is_impossible': True},\n  {'id': '10',\n   'question': 'What has AI enabled in the context of predictive threat detection?',\n   'answer': [{'text': 'automated defense mechanisms', 'answer_start': 267}],\n   'is_impossible': True},\n  {'id': '11',\n   'question': 'Which AI capabilities were developed over time for cybersecurity?',\n   'answer': [{'text': 'advanced machine learning and deep learning',\n     'answer_start': 181}],\n   'is_impossible': True},\n  {'id': '12',\n   'question': 'How do vendors utilize generative AI in cybersecurity?',\n   'answer': [{'text': 'to stay ahead of an ever-evolving threat landscape',\n     'answer_start': 410}],\n   'is_impossible': True},\n  {'id': '13',\n   'question': 'What does behavioral analytics detect in the context of AI?',\n   'answer': [{'text': 'anomalies like unusual logins or data transfers',\n     'answer_start': 100}],\n   'is_impossible': True},\n  {'id': '14',\n   'question': 'What aspect of AI tools helps vendors address cybersecurity threats?',\n   'answer': [{'text': 'leveraging tools like generative AI',\n     'answer_start': 354}],\n   'is_impossible': True},\n  {'id': '15',\n   'question': 'Which area of learning is mentioned alongside advanced machine learning in the context?',\n   'answer': [{'text': 'deep learning', 'answer_start': 198}],\n   'is_impossible': True},\n  {'id': '16',\n   'question': 'How do cybersecurity vendors maintain their edge in the threat landscape?',\n   'answer': [{'text': 'leveraging tools like generative AI',\n     'answer_start': 354}],\n   'is_impossible': True},\n  {'id': '17',\n   'question': 'What kind of threats does predictive threat detection aim to address?',\n   'answer': [{'text': 'an ever-evolving threat landscape',\n     'answer_start': 246}],\n   'is_impossible': True},\n  {'id': '18',\n   'question': 'What has been the role of AI since 2012 in cybersecurity?',\n   'answer': [{'text': 'behavioral analytics to detect anomalies like unusual logins or data transfers',\n     'answer_start': 69}],\n   'is_impossible': True},\n  {'id': '19',\n   'question': 'How is the threat landscape described in the context?',\n   'answer': [{'text': 'an ever-evolving threat landscape',\n     'answer_start': 246}],\n   'is_impossible': True}]}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"test[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:13:41.288014Z","iopub.execute_input":"2024-11-23T16:13:41.288910Z","iopub.status.idle":"2024-11-23T16:13:41.295055Z","shell.execute_reply.started":"2024-11-23T16:13:41.288874Z","shell.execute_reply":"2024-11-23T16:13:41.294037Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'context': 'Redmi Note 11 (Space Black, 4GB RAM, 64GB Storage)|90Hz FHD+ AMOLED Display | Qualcomm® Snapdragon™ 680-6nm | 33W Charger Included',\n 'qas': [{'id': '00001',\n   'is_impossible': False,\n   'question': 'What is the model name of the Redmi smartphone?',\n   'answers': [{'text': 'Redmi Note 11', 'answer_start': 0}]},\n  {'id': '00002',\n   'is_impossible': False,\n   'question': 'What is the color option available for the Redmi Note 11?',\n   'answers': [{'text': 'Space Black', 'answer_start': 15}]},\n  {'id': '00003',\n   'is_impossible': False,\n   'question': 'How much RAM does the Redmi Note 11 have?',\n   'answers': [{'text': '4GB', 'answer_start': 28}]},\n  {'id': '00004',\n   'is_impossible': False,\n   'question': 'What is the storage capacity of the Redmi Note 11?',\n   'answers': [{'text': '64GB', 'answer_start': 37}]},\n  {'id': '00005',\n   'is_impossible': False,\n   'question': 'What is the display feature of the Redmi Note 11?',\n   'answers': [{'text': '90Hz FHD+ AMOLED Display', 'answer_start': 51}]},\n  {'id': '00006',\n   'is_impossible': False,\n   'question': 'What is included in the package of the Redmi Note 11?',\n   'answers': [{'text': '33W Charger Included', 'answer_start': 110}]}]}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"!pip install simpletransformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:13:45.587321Z","iopub.execute_input":"2024-11-23T16:13:45.587943Z","iopub.status.idle":"2024-11-23T16:13:59.172863Z","shell.execute_reply.started":"2024-11-23T16:13:45.587911Z","shell.execute_reply":"2024-11-23T16:13:59.172033Z"}},"outputs":[{"name":"stdout","text":"Collecting simpletransformers\n  Downloading simpletransformers-0.70.1-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.32.3)\nRequirement already satisfied: tqdm>=4.47.0 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (4.66.4)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2024.5.15)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (4.45.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (3.0.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.14.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (1.2.2)\nCollecting seqeval (from simpletransformers)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.16.2)\nRequirement already satisfied: tensorboardx in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.6.2.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (2.2.2)\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.20.0)\nRequirement already satisfied: wandb>=0.10.32 in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.18.3)\nCollecting streamlit (from simpletransformers)\n  Downloading streamlit-1.40.1-py2.py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from simpletransformers) (0.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.25.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.4.5)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (2.15.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (70.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->simpletransformers) (2024.8.30)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->simpletransformers) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->simpletransformers) (3.9.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->simpletransformers) (2024.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (3.5.0)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.4.1)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (1.8.2)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.2.4)\nRequirement already satisfied: pillow<12,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (10.3.0)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (13.7.1)\nRequirement already satisfied: tenacity<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (8.3.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.12.2)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit->simpletransformers)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.4.1)\nRequirement already satisfied: watchdog<7,>=2.1.5 in /opt/conda/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.0.3)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.62.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.6)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.0.4)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.4)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.22.0)\nRequirement already satisfied: narwhals>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (1.9.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (4.0.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.11)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->simpletransformers) (3.1.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.5)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.1)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.18.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.2)\nDownloading simpletransformers-0.70.1-py3-none-any.whl (316 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading streamlit-1.40.1-py2.py3-none-any.whl (8.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=fb3ea720f64146b19bd460cea0d65e3735b5466a9c04d39621283d4fd30b2c1e\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: pydeck, seqeval, streamlit, simpletransformers\nSuccessfully installed pydeck-0.9.1 seqeval-1.2.2 simpletransformers-0.70.1 streamlit-1.40.1\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import logging\nfrom simpletransformers.question_answering import QuestionAnsweringModel, QuestionAnsweringArgs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:14:07.111230Z","iopub.execute_input":"2024-11-23T16:14:07.111586Z","iopub.status.idle":"2024-11-23T16:14:23.855957Z","shell.execute_reply.started":"2024-11-23T16:14:07.111555Z","shell.execute_reply":"2024-11-23T16:14:23.855077Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"#train_args are the parameters the QuestionAnswerringModel will use \ntrain_args = {\n    'overwrite_output_dir': True,\n    \"evaluate_during_training\": True,\n    \"max_seq_length\": 512,\n    \"num_train_epochs\": 25, #25, after experimentations\n    \"evaluate_during_training_steps\": 500,\n    \"save_model_every_epoch\": False,\n    \"save_eval_checkpoints\": False,\n    \"n_best_size\":16, #batch_size is another important argument\n    \"train_batch_size\": 16,\n    \"eval_batch_size\": 16\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:14:37.958270Z","iopub.execute_input":"2024-11-23T16:14:37.959101Z","iopub.status.idle":"2024-11-23T16:14:37.963419Z","shell.execute_reply.started":"2024-11-23T16:14:37.959069Z","shell.execute_reply":"2024-11-23T16:14:37.962527Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = QuestionAnsweringModel(\"bert\",\n                               \"bert-large-cased\", \n                               args = train_args,\n                               use_cuda=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:14:42.914243Z","iopub.execute_input":"2024-11-23T16:14:42.914560Z","iopub.status.idle":"2024-11-23T16:14:50.938900Z","shell.execute_reply.started":"2024-11-23T16:14:42.914535Z","shell.execute_reply":"2024-11-23T16:14:50.937971Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"609a0e7177144353909d491561a1f4fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a4e282f6e87416186eb1b7321a75b07"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f73607b1482c4d2c9fceaf27a2588b55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec89899a847c41a6ad0918d00cabd7f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1a1f72c024c48b09a7a28dffa111f57"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.train_model(train, eval_data=test)     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:15:00.564827Z","iopub.execute_input":"2024-11-23T16:15:00.565195Z","iopub.status.idle":"2024-11-23T16:39:28.559834Z","shell.execute_reply.started":"2024-11-23T16:15:00.565150Z","shell.execute_reply":"2024-11-23T16:39:28.556395Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nconvert squad examples to features: 100%|██████████| 282/282 [00:00<00:00, 304.21it/s]\nadd example index and unique id: 100%|██████████| 282/282 [00:00<00:00, 459873.14it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"494a4e5425b74b10b861b28bb306d3eb"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/simpletransformers/question_answering/question_answering_model.py:697: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = amp.GradScaler()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Epoch 1 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b193e7a91fd4870b855d6b20aaccb5a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/simpletransformers/question_answering/question_answering_model.py:720: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with amp.autocast():\n\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 517.10it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 241679.23it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f38cee6c02914183aa28c66e1a3b4aa5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/simpletransformers/question_answering/question_answering_model.py:1184: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with amp.autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Epoch 2 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75721b1841c34618a1c8d29e88e95380"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 500.76it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 171761.46it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fea885882fe64b9f8e3a847f6d903824"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 3 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d10d3a8dc88d4e9dadc2590ec6a162f3"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 488.31it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 181596.96it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33ade2dbb79c4e4a959fd553e16a74bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 4 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6697f8eaf7946969740692785173084"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 520.26it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 183908.66it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f823346befa4257a1462aa0a347128a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 5 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1885d5cbb8694f5ead1e19108d811078"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 502.47it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 214206.63it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89ca02ff5a444abfb448171b100e936b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 6 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3453b0a3804c4d7fb7a79359670c9489"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 514.51it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 255448.77it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"725e265eefd541bbb0b77ec29e43a6c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 7 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c398f985d8b42a4b64c76dc8bef1498"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 516.48it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 243034.44it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60dbd7a9e22540c092610a60ce842c7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 8 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13baa22fc6f646f38a40f9d43d52d781"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 505.67it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 204118.41it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"865c776db9fe47a9ac3ccb97f0de3b9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 9 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ccb2ec7935c473e9934d333f0426b98"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 510.39it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 177143.63it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"656dcd97645d4319b87cfac028ab5fad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 10 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa23bdef75204485802b7d51daeb431c"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 432.71it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 297536.44it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11d52ab44c384c4993957bf40b37b729"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 11 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f720048df4f47128bec6a1e522a93ba"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 518.46it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 194937.67it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d6a8d1f78cf4a8099c4690b97ce3e8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 12 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc41ff40ec8e4d7789ed1392a73dda84"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 513.76it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 190650.18it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c686cb71879c424e8cb9ae4f2bf91565"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 13 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8954522dcc04439096dc106fbd938745"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 517.21it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 224178.32it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2150b6a9cd345f4b278afc4e42363bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 14 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70a5bbbd7ad144f9be6dfabafc0749ba"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 515.33it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 231358.41it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"721ca904f0844fc7a868075de963cc39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 15 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"484b4e661542409a95f85ccadaac6822"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 510.09it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 203161.60it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ec4418e1844409aba9f47f3e6600089"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 16 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94cd7f956c9241daa12cef5e400cb4b2"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 515.78it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 247192.82it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a64244d4c6ca4737bca6e8d9267234dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 17 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6a4f51517ac4dbeac80b68a7dea1a03"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 505.08it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 183389.88it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9402bcbd4d2478da1e179c1dfee04a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 18 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea7dce123d3245b38521c0f828d125a9"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 506.34it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 220752.84it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c17709232b148cc9cc582a17ca23733"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 19 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c548aaed5f284c58921e1e8c11e8fa8b"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 511.50it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 194645.84it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adb6b8baa3d94d959a4d3d8597a7ec45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 20 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"111b977716d94ff99728c85d0c689245"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 519.08it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 195523.95it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab433b0855cb4aa99c17b25621c07593"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 21 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82f0c70dedd74cb6a419c0bb65f79c5d"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 514.31it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 223407.95it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c15ce260842b4604a3baf67201d2a63c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 22 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"874b54e231a5420bb64be495df048bd2"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 418.83it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 270882.13it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6ad9ef368d04b749d2dc5cd3b890260"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 23 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36bc53e1f4f4461a94db1ed258c813f5"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 523.45it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 248136.31it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f09501f9c564631a26b636dd54229ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 24 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8afeb205652428aa28e8a3477233457"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 515.03it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 215985.75it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a66df835c734b1eb311eae51efb5db4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running Epoch 25 of 25:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c26031952f34417bd6dba7924bc4380"}},"metadata":{}},{"name":"stderr","text":"\nconvert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 510.83it/s]\n\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 251010.47it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"705adfe8f7a94131a4e87d4467d8bc27"}},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(450,\n {'global_step': [18,\n   36,\n   54,\n   72,\n   90,\n   108,\n   126,\n   144,\n   162,\n   180,\n   198,\n   216,\n   234,\n   252,\n   270,\n   288,\n   306,\n   324,\n   342,\n   360,\n   378,\n   396,\n   414,\n   432,\n   450],\n  'correct': [0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0],\n  'similar': [9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9,\n   9],\n  'incorrect': [0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0,\n   0],\n  'train_loss': [0.952099621295929,\n   0.00020276903524063528,\n   6.114840653026477e-05,\n   4.1919945942936465e-05,\n   3.299712989246473e-05,\n   2.8461217880249023e-05,\n   2.49207023443887e-05,\n   2.35140323638916e-05,\n   2.0998715626774356e-05,\n   2.0742416381835938e-05,\n   1.8996001017512754e-05,\n   1.8513201212044805e-05,\n   1.7517804735689424e-05,\n   1.6450881958007812e-05,\n   1.6295909517793916e-05,\n   1.609325408935547e-05,\n   1.5246868315443862e-05,\n   1.4990568161010742e-05,\n   1.417398379999213e-05,\n   1.4162063962430693e-05,\n   1.5264748071786016e-05,\n   1.4495850336970761e-05,\n   1.4013052350492217e-05,\n   1.3780593690171372e-05,\n   1.3339519682631362e-05],\n  'eval_loss': [-3.994140625,\n   -7.71875,\n   -8.35546875,\n   -8.5546875,\n   -8.62890625,\n   -8.671875,\n   -8.70703125,\n   -8.73828125,\n   -8.76171875,\n   -8.78515625,\n   -8.80859375,\n   -8.83203125,\n   -8.84765625,\n   -8.86328125,\n   -8.87890625,\n   -8.89453125,\n   -8.90234375,\n   -8.91796875,\n   -8.92578125,\n   -8.93359375,\n   -8.9375,\n   -8.94140625,\n   -8.94140625,\n   -8.94921875,\n   -8.94921875]})"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"result, texts = model.eval_model(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:40:51.219314Z","iopub.execute_input":"2024-11-23T16:40:51.220147Z","iopub.status.idle":"2024-11-23T16:40:53.097461Z","shell.execute_reply.started":"2024-11-23T16:40:51.220104Z","shell.execute_reply":"2024-11-23T16:40:53.096674Z"}},"outputs":[{"name":"stderr","text":"convert squad examples to features: 100%|██████████| 31/31 [00:00<00:00, 479.28it/s]\nadd example index and unique id: 100%|██████████| 31/31 [00:00<00:00, 212456.58it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Evaluation:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7860ad9a80d42af8c3694ea6af8d258"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:41:15.926080Z","iopub.execute_input":"2024-11-23T16:41:15.926440Z","iopub.status.idle":"2024-11-23T16:41:15.932998Z","shell.execute_reply.started":"2024-11-23T16:41:15.926410Z","shell.execute_reply":"2024-11-23T16:41:15.932104Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'correct_text': {},\n 'similar_text': {'00001': {'truth': 'Oppo A78 5G',\n   'predicted': '',\n   'question': 'What is the model name of the Oppo smartphone?'},\n  '00002': {'truth': 'Glowing Black',\n   'predicted': '',\n   'question': 'What is the color option available for the Oppo A78 5G?'},\n  '00003': {'truth': '8GB',\n   'predicted': '',\n   'question': 'How much RAM does the Oppo A78 5G have?'},\n  '00004': {'truth': '5000 mAh',\n   'predicted': '',\n   'question': 'What is the battery capacity of the Oppo A78 5G?'},\n  '00005': {'truth': '33W SUPERVOOC Charger',\n   'predicted': '',\n   'question': 'What is the charging speed of the Oppo A78 5G?'},\n  '00006': {'truth': '50MP AI Camera',\n   'predicted': '',\n   'question': 'What is the resolution of the camera on the Oppo A78 5G?'},\n  '00007': {'truth': '90Hz Refresh Rate',\n   'predicted': '',\n   'question': 'What is the refresh rate of the display on the Oppo A78 5G?'},\n  '00008': {'truth': 'with No Cost EMI/Additional Exchange Offers',\n   'predicted': '',\n   'question': 'Are there any additional offers available for the Oppo A78 5G?'},\n  '00009': {'truth': 'Clean Android (No Bloatware)',\n   'predicted': '',\n   'question': 'What operating system does the Lava Blaze 5G use?'}},\n 'incorrect_text': {}}"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"print(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:41:50.273350Z","iopub.execute_input":"2024-11-23T16:41:50.274226Z","iopub.status.idle":"2024-11-23T16:41:50.278501Z","shell.execute_reply.started":"2024-11-23T16:41:50.274152Z","shell.execute_reply":"2024-11-23T16:41:50.277539Z"}},"outputs":[{"name":"stdout","text":"{'correct': 0, 'similar': 9, 'incorrect': 0, 'eval_loss': -8.94921875}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from simpletransformers.question_answering import QuestionAnsweringModel, QuestionAnsweringArgs\n \nmodel = QuestionAnsweringModel(\"bert\", \"/kaggle/working/outputs/best_model\")\n \n \n# Make predictions with the model\nto_predict = [\n    {\n       \"context\":\"Samsung Galaxy M14 5G (Smoky Teal, 6GB, 128GB Storage) | 50MP Triple Cam | 6000 mAh Battery | 5nm Octa-Core Processor | 12GB RAM with RAM Plus | Android 13 | Without Charger\"\n        ,\"qas\": [\n            {\n                \"question\": \"What is the model name of the Samsung smartphone?\",\n                \"id\": \"0\",\n            }\n        ],\n    }\n]\n \nanswers, probabilities = model.predict(to_predict, n_best_size=2)\nprint(answers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:46:37.768236Z","iopub.execute_input":"2024-11-23T16:46:37.769045Z","iopub.status.idle":"2024-11-23T16:46:38.582722Z","shell.execute_reply.started":"2024-11-23T16:46:37.768999Z","shell.execute_reply":"2024-11-23T16:46:38.581715Z"}},"outputs":[{"name":"stderr","text":"convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 142.83it/s]\nadd example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 9664.29it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce8f9a7c436b4686900e74e9666ad79f"}},"metadata":{}},{"name":"stdout","text":"[{'id': '0', 'answer': ['']}]\n","output_type":"stream"}],"execution_count":27}]}